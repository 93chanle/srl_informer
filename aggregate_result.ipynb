{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir('ray_tune/tune_SRL_POS_20_24_23-04-2023_00-21-33/')\n",
    "lst.str.startswith['my_prefix']\n",
    "[l for l in lst if 'my_prefix' in l][-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\srl_informer\\ray_tune\\\\exps\\\\linex\\\\tune_SRL_NEG_04_08_14-05-2023_20-56-01\\\\my_prefix_trainable_98cbe3be\\\\processed_result.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.normpath('d:\\srl_informer\\ray_tune\\exps\\linex\\\\tune_SRL_NEG_04_08_14-05-2023_20-56-01\\my_prefix_trainable_98cbe3be\\processed_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Dataset_Custom' on <module 'data.data_loader' from 'd:\\\\srl_informer\\\\data\\\\data_loader.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\srl_informer\\aggregate_result.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/srl_informer/aggregate_result.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mprocessed_result.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/srl_informer/aggregate_result.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     result \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39;49mload(f)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'Dataset_Custom' on <module 'data.data_loader' from 'd:\\\\srl_informer\\\\data\\\\data_loader.py'>"
     ]
    }
   ],
   "source": [
    "with open('processed_result.pkl','rb') as f:\n",
    "    result = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "experiment_types = [name for name in os.listdir(f'ray_tune/exps/')]\n",
    "\n",
    "result_table=pd.DataFrame(columns=['experiment_type',\n",
    "                                    'product_type',\n",
    "                                    'loss_type',\n",
    "                                    'model_pred_revenue',\n",
    "                                    'naive_pred_revenue',\n",
    "                                    #'pred_len',\n",
    "                                    'trainable_name',\n",
    "                                    'time_stamp'])\n",
    "    # experiment_type='informer_linex_loss'\n",
    "    \n",
    "for experiment_type in experiment_types:\n",
    "\n",
    "    lst = os.listdir(f'ray_tune/exps/{experiment_type}')\n",
    "    for product in lst:\n",
    "        \n",
    "        if 'xgb' in experiment_type:\n",
    "            product_type = '_'.join(product.split('_')[3:6])\n",
    "        else:\n",
    "            product_type = '_'.join(product.split('_')[2:5])\n",
    "\n",
    "        # trainable_name=[l for l in os.listdir(f'ray_tune/exps/{experiment_type}/{product}') if 'my_prefix' in l][0]\n",
    "        \n",
    "        trainable_names=[l for l in os.listdir(f'ray_tune/exps/{experiment_type}/{product}') if 'my_prefix' in l]\n",
    "        \n",
    "        for trainable_name in trainable_names:\n",
    "            result_dir = os.path.abspath(f'ray_tune/exps/{experiment_type}/{product}/{trainable_name}')\n",
    "            \n",
    "            try:\n",
    "                with open(f'{result_dir}/processed_result.pickle', 'rb') as f:\n",
    "                    result = pkl.load(f)\n",
    "            except FileNotFoundError:\n",
    "                print('error')\n",
    "            \n",
    "            else:\n",
    "                              \n",
    "                time_stamp='_'.join(lst[0].split('_')[-2:])\n",
    "                row = [experiment_type, product_type, result.args.loss, result.predict_revenue(result.pred), \n",
    "                    result.predict_revenue(result.pred_naive),\n",
    "                    #result.pred_len, \n",
    "                    trainable_name,\n",
    "                    time_stamp]\n",
    "                \n",
    "                result_table.loc[len(result_table)] = row\n",
    "            \n",
    "        \n",
    "    # print(f'{result.predict_revenue(result.pred_naive)=}')\n",
    "    # print(f'{result.predict_revenue(result.pred)=}')\n",
    "    # print(f'{result.pred_len=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = result_table.groupby(['experiment_type', 'product_type'])['model_pred_revenue'].transform(max) == result_table['model_pred_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_table[idx].sort_values(by=['product_type', 'experiment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['percent_improved'] = np.round((result['model_pred_revenue']-result['naive_pred_revenue']) / result['naive_pred_revenue'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>product_type</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>model_pred_revenue</th>\n",
       "      <th>naive_pred_revenue</th>\n",
       "      <th>trainable_name</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>percent_improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linex</td>\n",
       "      <td>2201.75</td>\n",
       "      <td>1273.07</td>\n",
       "      <td>my_prefix_trainable_02df154f</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1913.80</td>\n",
       "      <td>1273.07</td>\n",
       "      <td>my_prefix_trainable_b6dcde0a</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1905.73</td>\n",
       "      <td>1273.07</td>\n",
       "      <td>my_prefix_trainable_a0e9a25c</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2111.40</td>\n",
       "      <td>1273.07</td>\n",
       "      <td>my_prefix_trainable_e6962f19</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1684.85</td>\n",
       "      <td>904.79</td>\n",
       "      <td>my_prefix_trainable_336ee99b</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1488.11</td>\n",
       "      <td>904.79</td>\n",
       "      <td>my_prefix_trainable_c0847a5e</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1722.95</td>\n",
       "      <td>904.79</td>\n",
       "      <td>my_prefix_trainable_2919f9f4</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linex</td>\n",
       "      <td>2338.06</td>\n",
       "      <td>837.80</td>\n",
       "      <td>my_prefix_trainable_a7c883a4</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1632.18</td>\n",
       "      <td>837.80</td>\n",
       "      <td>my_prefix_trainable_1b9f58e7</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1521.41</td>\n",
       "      <td>837.80</td>\n",
       "      <td>my_prefix_trainable_396f0b41</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1645.85</td>\n",
       "      <td>837.80</td>\n",
       "      <td>my_prefix_trainable_849ab6d2</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linex</td>\n",
       "      <td>2668.45</td>\n",
       "      <td>1894.15</td>\n",
       "      <td>my_prefix_trainable_1d9a9247</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2480.49</td>\n",
       "      <td>1894.15</td>\n",
       "      <td>my_prefix_trainable_2b02549d</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>rmse</td>\n",
       "      <td>2137.51</td>\n",
       "      <td>1894.15</td>\n",
       "      <td>my_prefix_trainable_c528da7d</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2533.08</td>\n",
       "      <td>1894.15</td>\n",
       "      <td>my_prefix_trainable_6cfd5ff5</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linex</td>\n",
       "      <td>1262.50</td>\n",
       "      <td>812.36</td>\n",
       "      <td>my_prefix_trainable_0601ded7</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1248.63</td>\n",
       "      <td>812.36</td>\n",
       "      <td>my_prefix_trainable_74d0a30c</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>rmse</td>\n",
       "      <td>914.37</td>\n",
       "      <td>812.36</td>\n",
       "      <td>my_prefix_trainable_8a76f3a7</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1291.33</td>\n",
       "      <td>812.36</td>\n",
       "      <td>my_prefix_trainable_6514330a</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linex</td>\n",
       "      <td>595.41</td>\n",
       "      <td>391.70</td>\n",
       "      <td>my_prefix_trainable_eee1d153</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linlin</td>\n",
       "      <td>510.85</td>\n",
       "      <td>391.70</td>\n",
       "      <td>my_prefix_trainable_d7d28abf</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>rmse</td>\n",
       "      <td>537.55</td>\n",
       "      <td>391.70</td>\n",
       "      <td>my_prefix_trainable_9bd63dcc</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>602.13</td>\n",
       "      <td>391.70</td>\n",
       "      <td>my_prefix_trainable_09862b72</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_00_04</td>\n",
       "      <td>linex</td>\n",
       "      <td>626.91</td>\n",
       "      <td>270.52</td>\n",
       "      <td>my_prefix_trainable_b8294c50</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_00_04</td>\n",
       "      <td>linlin</td>\n",
       "      <td>590.70</td>\n",
       "      <td>270.52</td>\n",
       "      <td>my_prefix_trainable_98737804</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_00_04</td>\n",
       "      <td>rmse</td>\n",
       "      <td>570.04</td>\n",
       "      <td>270.52</td>\n",
       "      <td>my_prefix_trainable_3ac3eab0</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_00_04</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>580.98</td>\n",
       "      <td>270.52</td>\n",
       "      <td>my_prefix_trainable_71cb547b</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_04_08</td>\n",
       "      <td>linex</td>\n",
       "      <td>1116.69</td>\n",
       "      <td>503.77</td>\n",
       "      <td>my_prefix_trainable_f7378da3</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_04_08</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1085.83</td>\n",
       "      <td>503.77</td>\n",
       "      <td>my_prefix_trainable_503fe45e</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_04_08</td>\n",
       "      <td>rmse</td>\n",
       "      <td>746.73</td>\n",
       "      <td>503.77</td>\n",
       "      <td>my_prefix_trainable_bd4594f1</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_04_08</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1072.26</td>\n",
       "      <td>503.77</td>\n",
       "      <td>my_prefix_trainable_839e6a01</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_08_12</td>\n",
       "      <td>linex</td>\n",
       "      <td>2217.95</td>\n",
       "      <td>1147.58</td>\n",
       "      <td>my_prefix_trainable_e55ebe97</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_08_12</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2060.84</td>\n",
       "      <td>1147.58</td>\n",
       "      <td>my_prefix_trainable_af8ab481</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_08_12</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1827.83</td>\n",
       "      <td>1147.58</td>\n",
       "      <td>my_prefix_trainable_13b48ec8</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_08_12</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2403.08</td>\n",
       "      <td>1147.58</td>\n",
       "      <td>my_prefix_trainable_bdfb2be4</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_12_16</td>\n",
       "      <td>linex</td>\n",
       "      <td>1000.07</td>\n",
       "      <td>529.87</td>\n",
       "      <td>my_prefix_trainable_e64de62f</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_12_16</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1154.64</td>\n",
       "      <td>529.87</td>\n",
       "      <td>my_prefix_trainable_34815090</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_12_16</td>\n",
       "      <td>rmse</td>\n",
       "      <td>621.50</td>\n",
       "      <td>529.87</td>\n",
       "      <td>my_prefix_trainable_c70447ad</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_12_16</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>932.95</td>\n",
       "      <td>529.87</td>\n",
       "      <td>my_prefix_trainable_4ca22035</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_16_20</td>\n",
       "      <td>linex</td>\n",
       "      <td>3437.09</td>\n",
       "      <td>1691.91</td>\n",
       "      <td>my_prefix_trainable_19ba0fed</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_16_20</td>\n",
       "      <td>linlin</td>\n",
       "      <td>3396.62</td>\n",
       "      <td>1691.91</td>\n",
       "      <td>my_prefix_trainable_15e4fda1</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_16_20</td>\n",
       "      <td>rmse</td>\n",
       "      <td>2710.72</td>\n",
       "      <td>1691.91</td>\n",
       "      <td>my_prefix_trainable_8d4d43e3</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_16_20</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>3509.21</td>\n",
       "      <td>1691.91</td>\n",
       "      <td>my_prefix_trainable_6f5e16a6</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>linex</td>\n",
       "      <td>POS_20_24</td>\n",
       "      <td>linex</td>\n",
       "      <td>1773.21</td>\n",
       "      <td>976.21</td>\n",
       "      <td>my_prefix_trainable_d6d82ea2</td>\n",
       "      <td>17-05-2023_20-58-59</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>linlin</td>\n",
       "      <td>POS_20_24</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2080.46</td>\n",
       "      <td>976.21</td>\n",
       "      <td>my_prefix_trainable_86c02004</td>\n",
       "      <td>17-05-2023_10-30-03</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rmse</td>\n",
       "      <td>POS_20_24</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1682.64</td>\n",
       "      <td>976.21</td>\n",
       "      <td>my_prefix_trainable_06618f53</td>\n",
       "      <td>18-05-2023_17-21-43</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>POS_20_24</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2135.11</td>\n",
       "      <td>976.21</td>\n",
       "      <td>my_prefix_trainable_ae1547b7</td>\n",
       "      <td>18-05-2023_06-00-55</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_type product_type loss_type  model_pred_revenue  \\\n",
       "0            linex    NEG_00_04     linex             2201.75   \n",
       "23          linlin    NEG_00_04    linlin             1913.80   \n",
       "46            rmse    NEG_00_04      rmse             1905.73   \n",
       "70          w_rmse    NEG_00_04    w_rmse             2111.40   \n",
       "24          linlin    NEG_04_08    linlin             1684.85   \n",
       "49            rmse    NEG_04_08      rmse             1488.11   \n",
       "72          w_rmse    NEG_04_08    w_rmse             1722.95   \n",
       "3            linex    NEG_08_12     linex             2338.06   \n",
       "26          linlin    NEG_08_12    linlin             1632.18   \n",
       "50            rmse    NEG_08_12      rmse             1521.41   \n",
       "75          w_rmse    NEG_08_12    w_rmse             1645.85   \n",
       "4            linex    NEG_12_16     linex             2668.45   \n",
       "28          linlin    NEG_12_16    linlin             2480.49   \n",
       "53            rmse    NEG_12_16      rmse             2137.51   \n",
       "76          w_rmse    NEG_12_16    w_rmse             2533.08   \n",
       "6            linex    NEG_16_20     linex             1262.50   \n",
       "30          linlin    NEG_16_20    linlin             1248.63   \n",
       "55            rmse    NEG_16_20      rmse              914.37   \n",
       "78          w_rmse    NEG_16_20    w_rmse             1291.33   \n",
       "9            linex    NEG_20_24     linex              595.41   \n",
       "33          linlin    NEG_20_24    linlin              510.85   \n",
       "56            rmse    NEG_20_24      rmse              537.55   \n",
       "80          w_rmse    NEG_20_24    w_rmse              602.13   \n",
       "11           linex    POS_00_04     linex              626.91   \n",
       "35          linlin    POS_00_04    linlin              590.70   \n",
       "58            rmse    POS_00_04      rmse              570.04   \n",
       "83          w_rmse    POS_00_04    w_rmse              580.98   \n",
       "13           linex    POS_04_08     linex             1116.69   \n",
       "36          linlin    POS_04_08    linlin             1085.83   \n",
       "60            rmse    POS_04_08      rmse              746.73   \n",
       "84          w_rmse    POS_04_08    w_rmse             1072.26   \n",
       "15           linex    POS_08_12     linex             2217.95   \n",
       "38          linlin    POS_08_12    linlin             2060.84   \n",
       "62            rmse    POS_08_12      rmse             1827.83   \n",
       "87          w_rmse    POS_08_12    w_rmse             2403.08   \n",
       "17           linex    POS_12_16     linex             1000.07   \n",
       "40          linlin    POS_12_16    linlin             1154.64   \n",
       "65            rmse    POS_12_16      rmse              621.50   \n",
       "88          w_rmse    POS_12_16    w_rmse              932.95   \n",
       "18           linex    POS_16_20     linex             3437.09   \n",
       "43          linlin    POS_16_20    linlin             3396.62   \n",
       "67            rmse    POS_16_20      rmse             2710.72   \n",
       "91          w_rmse    POS_16_20    w_rmse             3509.21   \n",
       "20           linex    POS_20_24     linex             1773.21   \n",
       "44          linlin    POS_20_24    linlin             2080.46   \n",
       "68            rmse    POS_20_24      rmse             1682.64   \n",
       "93          w_rmse    POS_20_24    w_rmse             2135.11   \n",
       "\n",
       "    naive_pred_revenue                trainable_name           time_stamp  \\\n",
       "0              1273.07  my_prefix_trainable_02df154f  17-05-2023_20-58-59   \n",
       "23             1273.07  my_prefix_trainable_b6dcde0a  17-05-2023_10-30-03   \n",
       "46             1273.07  my_prefix_trainable_a0e9a25c  18-05-2023_17-21-43   \n",
       "70             1273.07  my_prefix_trainable_e6962f19  18-05-2023_06-00-55   \n",
       "24              904.79  my_prefix_trainable_336ee99b  17-05-2023_10-30-03   \n",
       "49              904.79  my_prefix_trainable_c0847a5e  18-05-2023_17-21-43   \n",
       "72              904.79  my_prefix_trainable_2919f9f4  18-05-2023_06-00-55   \n",
       "3               837.80  my_prefix_trainable_a7c883a4  17-05-2023_20-58-59   \n",
       "26              837.80  my_prefix_trainable_1b9f58e7  17-05-2023_10-30-03   \n",
       "50              837.80  my_prefix_trainable_396f0b41  18-05-2023_17-21-43   \n",
       "75              837.80  my_prefix_trainable_849ab6d2  18-05-2023_06-00-55   \n",
       "4              1894.15  my_prefix_trainable_1d9a9247  17-05-2023_20-58-59   \n",
       "28             1894.15  my_prefix_trainable_2b02549d  17-05-2023_10-30-03   \n",
       "53             1894.15  my_prefix_trainable_c528da7d  18-05-2023_17-21-43   \n",
       "76             1894.15  my_prefix_trainable_6cfd5ff5  18-05-2023_06-00-55   \n",
       "6               812.36  my_prefix_trainable_0601ded7  17-05-2023_20-58-59   \n",
       "30              812.36  my_prefix_trainable_74d0a30c  17-05-2023_10-30-03   \n",
       "55              812.36  my_prefix_trainable_8a76f3a7  18-05-2023_17-21-43   \n",
       "78              812.36  my_prefix_trainable_6514330a  18-05-2023_06-00-55   \n",
       "9               391.70  my_prefix_trainable_eee1d153  17-05-2023_20-58-59   \n",
       "33              391.70  my_prefix_trainable_d7d28abf  17-05-2023_10-30-03   \n",
       "56              391.70  my_prefix_trainable_9bd63dcc  18-05-2023_17-21-43   \n",
       "80              391.70  my_prefix_trainable_09862b72  18-05-2023_06-00-55   \n",
       "11              270.52  my_prefix_trainable_b8294c50  17-05-2023_20-58-59   \n",
       "35              270.52  my_prefix_trainable_98737804  17-05-2023_10-30-03   \n",
       "58              270.52  my_prefix_trainable_3ac3eab0  18-05-2023_17-21-43   \n",
       "83              270.52  my_prefix_trainable_71cb547b  18-05-2023_06-00-55   \n",
       "13              503.77  my_prefix_trainable_f7378da3  17-05-2023_20-58-59   \n",
       "36              503.77  my_prefix_trainable_503fe45e  17-05-2023_10-30-03   \n",
       "60              503.77  my_prefix_trainable_bd4594f1  18-05-2023_17-21-43   \n",
       "84              503.77  my_prefix_trainable_839e6a01  18-05-2023_06-00-55   \n",
       "15             1147.58  my_prefix_trainable_e55ebe97  17-05-2023_20-58-59   \n",
       "38             1147.58  my_prefix_trainable_af8ab481  17-05-2023_10-30-03   \n",
       "62             1147.58  my_prefix_trainable_13b48ec8  18-05-2023_17-21-43   \n",
       "87             1147.58  my_prefix_trainable_bdfb2be4  18-05-2023_06-00-55   \n",
       "17              529.87  my_prefix_trainable_e64de62f  17-05-2023_20-58-59   \n",
       "40              529.87  my_prefix_trainable_34815090  17-05-2023_10-30-03   \n",
       "65              529.87  my_prefix_trainable_c70447ad  18-05-2023_17-21-43   \n",
       "88              529.87  my_prefix_trainable_4ca22035  18-05-2023_06-00-55   \n",
       "18             1691.91  my_prefix_trainable_19ba0fed  17-05-2023_20-58-59   \n",
       "43             1691.91  my_prefix_trainable_15e4fda1  17-05-2023_10-30-03   \n",
       "67             1691.91  my_prefix_trainable_8d4d43e3  18-05-2023_17-21-43   \n",
       "91             1691.91  my_prefix_trainable_6f5e16a6  18-05-2023_06-00-55   \n",
       "20              976.21  my_prefix_trainable_d6d82ea2  17-05-2023_20-58-59   \n",
       "44              976.21  my_prefix_trainable_86c02004  17-05-2023_10-30-03   \n",
       "68              976.21  my_prefix_trainable_06618f53  18-05-2023_17-21-43   \n",
       "93              976.21  my_prefix_trainable_ae1547b7  18-05-2023_06-00-55   \n",
       "\n",
       "    percent_improved  \n",
       "0               0.73  \n",
       "23              0.50  \n",
       "46              0.50  \n",
       "70              0.66  \n",
       "24              0.86  \n",
       "49              0.64  \n",
       "72              0.90  \n",
       "3               1.79  \n",
       "26              0.95  \n",
       "50              0.82  \n",
       "75              0.96  \n",
       "4               0.41  \n",
       "28              0.31  \n",
       "53              0.13  \n",
       "76              0.34  \n",
       "6               0.55  \n",
       "30              0.54  \n",
       "55              0.13  \n",
       "78              0.59  \n",
       "9               0.52  \n",
       "33              0.30  \n",
       "56              0.37  \n",
       "80              0.54  \n",
       "11              1.32  \n",
       "35              1.18  \n",
       "58              1.11  \n",
       "83              1.15  \n",
       "13              1.22  \n",
       "36              1.16  \n",
       "60              0.48  \n",
       "84              1.13  \n",
       "15              0.93  \n",
       "38              0.80  \n",
       "62              0.59  \n",
       "87              1.09  \n",
       "17              0.89  \n",
       "40              1.18  \n",
       "65              0.17  \n",
       "88              0.76  \n",
       "18              1.03  \n",
       "43              1.01  \n",
       "67              0.60  \n",
       "91              1.07  \n",
       "20              0.82  \n",
       "44              1.13  \n",
       "68              0.72  \n",
       "93              1.19  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_type</th>\n",
       "      <th>percent_improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linex</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linlin</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loss_type  percent_improved\n",
       "0     linex              0.93\n",
       "1    linlin              0.83\n",
       "2      rmse              0.52\n",
       "3    w_rmse              0.86"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average improvement among loss functions (in comparison with naive prediction)\n",
    "\n",
    "result.groupby('loss_type', as_index=False)['percent_improved'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = result_table.groupby(by=['experiment_type', 'product_type'], as_index=False).max('model_pred_revenue').sort_values(by=['product_type', 'experiment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>product_type</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>model_pred_revenue</th>\n",
       "      <th>naive_pred_revenue</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linex</td>\n",
       "      <td>1558.55</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linex</td>\n",
       "      <td>1796.44</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1696.52</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>linlin</td>\n",
       "      <td>374.04</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1563.04</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1289.72</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1524.10</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_00_04</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1884.37</td>\n",
       "      <td>1261.16</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>linex</td>\n",
       "      <td>1229.84</td>\n",
       "      <td>938.48</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>linex</td>\n",
       "      <td>1497.29</td>\n",
       "      <td>938.48</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>linlin</td>\n",
       "      <td>1412.48</td>\n",
       "      <td>938.48</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>linlin</td>\n",
       "      <td>265.06</td>\n",
       "      <td>938.48</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>rmse</td>\n",
       "      <td>976.96</td>\n",
       "      <td>938.48</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1163.38</td>\n",
       "      <td>938.48</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_04_08</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1560.90</td>\n",
       "      <td>938.48</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linex</td>\n",
       "      <td>2926.05</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linex</td>\n",
       "      <td>2598.80</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linlin</td>\n",
       "      <td>637.37</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2886.83</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>rmse</td>\n",
       "      <td>2477.98</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1828.33</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2772.23</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_08_12</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>2359.68</td>\n",
       "      <td>1590.52</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linex</td>\n",
       "      <td>5189.23</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linex</td>\n",
       "      <td>6292.67</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linlin</td>\n",
       "      <td>6003.53</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2357.71</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>rmse</td>\n",
       "      <td>5100.26</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>rmse</td>\n",
       "      <td>4900.59</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>6159.38</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_12_16</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>5380.38</td>\n",
       "      <td>4828.76</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linex</td>\n",
       "      <td>2026.90</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linex</td>\n",
       "      <td>2121.27</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linlin</td>\n",
       "      <td>412.57</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>linlin</td>\n",
       "      <td>2163.30</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1779.28</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1760.94</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_16_20</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>1967.50</td>\n",
       "      <td>1422.60</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linex</td>\n",
       "      <td>600.21</td>\n",
       "      <td>427.87</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linex</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linex</td>\n",
       "      <td>527.87</td>\n",
       "      <td>427.87</td>\n",
       "      <td>14-05-2023_19-50-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linlin</td>\n",
       "      <td>82.64</td>\n",
       "      <td>427.87</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>linlin</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>linlin</td>\n",
       "      <td>581.42</td>\n",
       "      <td>427.87</td>\n",
       "      <td>14-05-2023_12-45-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>rmse</td>\n",
       "      <td>479.55</td>\n",
       "      <td>427.87</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>rmse</td>\n",
       "      <td>486.90</td>\n",
       "      <td>427.87</td>\n",
       "      <td>15-05-2023_10-44-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>483.10</td>\n",
       "      <td>427.87</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>w_rmse</td>\n",
       "      <td>NEG_20_24</td>\n",
       "      <td>w_rmse</td>\n",
       "      <td>594.74</td>\n",
       "      <td>427.87</td>\n",
       "      <td>15-05-2023_03-10-00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_type product_type loss_type  model_pred_revenue  \\\n",
       "0            linex    NEG_00_04     linex             1558.55   \n",
       "1            linex    NEG_00_04     linex             1796.44   \n",
       "12          linlin    NEG_00_04    linlin             1696.52   \n",
       "13          linlin    NEG_00_04    linlin              374.04   \n",
       "24            rmse    NEG_00_04      rmse             1563.04   \n",
       "25            rmse    NEG_00_04      rmse             1289.72   \n",
       "35          w_rmse    NEG_00_04    w_rmse             1524.10   \n",
       "36          w_rmse    NEG_00_04    w_rmse             1884.37   \n",
       "2            linex    NEG_04_08     linex             1229.84   \n",
       "3            linex    NEG_04_08     linex             1497.29   \n",
       "14          linlin    NEG_04_08    linlin             1412.48   \n",
       "15          linlin    NEG_04_08    linlin              265.06   \n",
       "26            rmse    NEG_04_08      rmse              976.96   \n",
       "27            rmse    NEG_04_08      rmse             1163.38   \n",
       "37          w_rmse    NEG_04_08    w_rmse             1560.90   \n",
       "4            linex    NEG_08_12     linex             2926.05   \n",
       "5            linex    NEG_08_12     linex             2598.80   \n",
       "16          linlin    NEG_08_12    linlin              637.37   \n",
       "17          linlin    NEG_08_12    linlin             2886.83   \n",
       "28            rmse    NEG_08_12      rmse             2477.98   \n",
       "29            rmse    NEG_08_12      rmse             1828.33   \n",
       "38          w_rmse    NEG_08_12    w_rmse             2772.23   \n",
       "39          w_rmse    NEG_08_12    w_rmse             2359.68   \n",
       "6            linex    NEG_12_16     linex             5189.23   \n",
       "7            linex    NEG_12_16     linex             6292.67   \n",
       "18          linlin    NEG_12_16    linlin             6003.53   \n",
       "19          linlin    NEG_12_16    linlin             2357.71   \n",
       "30            rmse    NEG_12_16      rmse             5100.26   \n",
       "31            rmse    NEG_12_16      rmse             4900.59   \n",
       "40          w_rmse    NEG_12_16    w_rmse             6159.38   \n",
       "41          w_rmse    NEG_12_16    w_rmse             5380.38   \n",
       "8            linex    NEG_16_20     linex             2026.90   \n",
       "9            linex    NEG_16_20     linex             2121.27   \n",
       "20          linlin    NEG_16_20    linlin              412.57   \n",
       "21          linlin    NEG_16_20    linlin             2163.30   \n",
       "32            rmse    NEG_16_20      rmse             1779.28   \n",
       "42          w_rmse    NEG_16_20    w_rmse             1760.94   \n",
       "43          w_rmse    NEG_16_20    w_rmse             1967.50   \n",
       "10           linex    NEG_20_24     linex              600.21   \n",
       "11           linex    NEG_20_24     linex              527.87   \n",
       "22          linlin    NEG_20_24    linlin               82.64   \n",
       "23          linlin    NEG_20_24    linlin              581.42   \n",
       "33            rmse    NEG_20_24      rmse              479.55   \n",
       "34            rmse    NEG_20_24      rmse              486.90   \n",
       "44          w_rmse    NEG_20_24    w_rmse              483.10   \n",
       "45          w_rmse    NEG_20_24    w_rmse              594.74   \n",
       "\n",
       "    naive_pred_revenue           time_stamp  \n",
       "0              1261.16  14-05-2023_19-50-10  \n",
       "1              1261.16  14-05-2023_19-50-10  \n",
       "12             1261.16  14-05-2023_12-45-51  \n",
       "13             1261.16  14-05-2023_12-45-51  \n",
       "24             1261.16  15-05-2023_10-44-05  \n",
       "25             1261.16  15-05-2023_10-44-05  \n",
       "35             1261.16  15-05-2023_03-10-00  \n",
       "36             1261.16  15-05-2023_03-10-00  \n",
       "2               938.48  14-05-2023_19-50-10  \n",
       "3               938.48  14-05-2023_19-50-10  \n",
       "14              938.48  14-05-2023_12-45-51  \n",
       "15              938.48  14-05-2023_12-45-51  \n",
       "26              938.48  15-05-2023_10-44-05  \n",
       "27              938.48  15-05-2023_10-44-05  \n",
       "37              938.48  15-05-2023_03-10-00  \n",
       "4              1590.52  14-05-2023_19-50-10  \n",
       "5              1590.52  14-05-2023_19-50-10  \n",
       "16             1590.52  14-05-2023_12-45-51  \n",
       "17             1590.52  14-05-2023_12-45-51  \n",
       "28             1590.52  15-05-2023_10-44-05  \n",
       "29             1590.52  15-05-2023_10-44-05  \n",
       "38             1590.52  15-05-2023_03-10-00  \n",
       "39             1590.52  15-05-2023_03-10-00  \n",
       "6              4828.76  14-05-2023_19-50-10  \n",
       "7              4828.76  14-05-2023_19-50-10  \n",
       "18             4828.76  14-05-2023_12-45-51  \n",
       "19             4828.76  14-05-2023_12-45-51  \n",
       "30             4828.76  15-05-2023_10-44-05  \n",
       "31             4828.76  15-05-2023_10-44-05  \n",
       "40             4828.76  15-05-2023_03-10-00  \n",
       "41             4828.76  15-05-2023_03-10-00  \n",
       "8              1422.60  14-05-2023_19-50-10  \n",
       "9              1422.60  14-05-2023_19-50-10  \n",
       "20             1422.60  14-05-2023_12-45-51  \n",
       "21             1422.60  14-05-2023_12-45-51  \n",
       "32             1422.60  15-05-2023_10-44-05  \n",
       "42             1422.60  15-05-2023_03-10-00  \n",
       "43             1422.60  15-05-2023_03-10-00  \n",
       "10              427.87  14-05-2023_19-50-10  \n",
       "11              427.87  14-05-2023_19-50-10  \n",
       "22              427.87  14-05-2023_12-45-51  \n",
       "23              427.87  14-05-2023_12-45-51  \n",
       "33              427.87  15-05-2023_10-44-05  \n",
       "34              427.87  15-05-2023_10-44-05  \n",
       "44              427.87  15-05-2023_03-10-00  \n",
       "45              427.87  15-05-2023_03-10-00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table.sort_values(by=['product_type', 'experiment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [0.8, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\srl_informer\\aggregate_result.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/srl_informer/aggregate_result.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39msum\u001b[39m(a) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "sum(a) == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double-check attns output compared with model args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='./results'\n",
    "result_path='29-07-2023_13-06-19_SRL_NEG_00_04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_path+'/'+result_path+'/'+'processed_result.pickle', 'rb') as f:\n",
    "    result = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data='SRL_NEG_00_04', model='informer', loss='linex', linex_weight=0.05, seq_len=64, label_len=30, pred_len=1, timestamp='29-07-2023_13-06-19', root_path='C:\\\\VirtualDrives\\\\D\\\\srl_informer\\\\data\\\\processed\\\\SRL', data_path='SRL_NEG_00_04.csv', features='S', cols=None, itr=2, train_epochs=3, scale='none', target='capacity_price', freq='d', checkpoints='./checkpoints/', enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=3, d_layers=2, s_layers=[3, 2, 1], d_ff=24, factor=4, padding=0, distil=True, dropout=0.05, attn='prob', embed='timeF', activation='gelu', output_attention=True, do_predict=False, mix=True, num_workers=0, batch_size=32, patience=3, learning_rate=0.0001, des='test', lradj='type1', use_amp=False, inverse=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', tune_num_samples=50, detail_freq='d')\n"
     ]
    }
   ],
   "source": [
    "print(result.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.data.seqs_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of result.attns:\n",
    "\n",
    "batches -> types of attn (enc, dec, cross) -> no. of layers -> [-, -, -, -]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.attns) # number of batches + rest batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = result.attns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['enc_attns']) # Should = args.e_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = batch['enc_attns']\n",
    "dec = batch['dec_self_attn']\n",
    "cross = batch['dec_cross_attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 64, 64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 32, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 16, 16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [B, H, label_len+pred_len, label_len+pred_len]\n",
    "\n",
    "enc[0].shape\n",
    "enc[1].shape\n",
    "enc[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 31, 31])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 31, 31])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [B, H, label_len+pred_len, label_len+pred_len]\n",
    "\n",
    "dec[0].shape\n",
    "dec[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 31, 16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 31, 16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [B, H, label_len+pred_len, label_len+pred_len]\n",
    "\n",
    "cross[0].shape\n",
    "cross[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_attns = []\n",
    "dec_attns = []\n",
    "cross_attns = []\n",
    "\n",
    "for attn in result.attns:\n",
    "    enc_attns.append(attn['enc_attns'])\n",
    "    dec_attns.append(attn['dec_self_attn'])\n",
    "    cross_attns.append(attn['dec_cross_attn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 64, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_attns[0][0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cle\\AppData\\Local\\miniforge3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Studies:\n",
    "    def __init__(self, root_path='./optuna_studies/'):\n",
    "        self.root_path = root_path\n",
    "        self.studies = self.get_studies(None)\n",
    "    \n",
    "    def _choose_studies_to_get(self, conditions, mode='and'):\n",
    "        \n",
    "        study_paths = [path for path in os.listdir(self.root_path) if path.startswith('tune_informer_SRL')]\n",
    "        # study_names = [study_path.removeprefix('tune_informer_SRL').removesuffix('.db') for study_path in study_paths]     \n",
    "        if conditions is not None:\n",
    "            if 'rmse' in conditions:\n",
    "                paths = [path for path in study_paths if self._check_strings(conditions, path, mode)]\n",
    "                return [path for path in paths if 'wrmse' not in path]\n",
    "            else:\n",
    "                return [path for path in study_paths if self._check_strings(conditions, path, mode)]\n",
    "        else: return study_paths\n",
    "    \n",
    "    def get_studies(self, conditions, mode='and'):\n",
    "        studies = {}\n",
    "        studies_df = {}        \n",
    "        study_paths = self._choose_studies_to_get(conditions, mode)\n",
    "        study_names = [study_path.removeprefix('tune_informer_SRL_').removesuffix('.db') for study_path in study_paths]   \n",
    "        # study_names = ['_'.join(path.split('_')[3:7]) for path in study_paths]\n",
    "    \n",
    "        for (study_path, study_name) in zip(study_paths, study_names):\n",
    "            study = self._get_study(study_path)            \n",
    "            studies[study_name] = study\n",
    "        #     # study.trials_dataframe()\n",
    "        #     # study.best_trials()\n",
    "        #     studies_df[study_name] = study.trials_dataframe()\n",
    "        return studies\n",
    "        # self.studies_df = studies_df\n",
    "        \n",
    "    def _get_study(self, study_path):\n",
    "    # assert any(var is not None for var in (loss, time_slot, direction)), 'Need at least loss product name'\n",
    "    # if loss is not None:\n",
    "    #     assert loss in ['rmse', 'linex', 'linlin', 'wrmse'], 'Invalid loss!'\n",
    "    # if direction is not None:\n",
    "    #     assert direction in ['NEG', 'POS'], 'Direction is one of [NEG, POS].'\n",
    "    # if time_slot is not None:   \n",
    "    #     assert time_slot in ['00_04', '04_08', '08_12', '12_16', '16_20', '20_24'], 'Invalid time slot!'\n",
    "\n",
    "        study_name = study_path.removesuffix('.db')  # Unique identifier of the study\n",
    "        storage_name = f\"sqlite:///{self.root_path}/{study_path}\"\n",
    "        study = optuna.create_study(study_name=study_name, storage=storage_name,\n",
    "                                    load_if_exists=True,\n",
    "                                    )\n",
    "        return study\n",
    "    \n",
    "    def _check_strings(self, list_of_strings, target_string, mode='and'):\n",
    "        if mode == 'or':\n",
    "            for s in list_of_strings:\n",
    "                if s in target_string:\n",
    "                    return True\n",
    "            return False\n",
    "        if mode == 'and':\n",
    "            for s in list_of_strings:\n",
    "                if s not in target_string:\n",
    "                    return False\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:20:50,370]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_20_24_wrmse_26-07-2023_17-08-37' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# study_name = study_path.removesuffix('.db')  # Unique identifier of the study\n",
    "storage_name = f\"sqlite:///./optuna_studies/tune_informer_SRL_POS_20_24_wrmse_26-07-2023_17-08-37\"\n",
    "study = optuna.create_study(study_name='tune_informer_SRL_POS_20_24_wrmse_26-07-2023_17-08-37', storage=storage_name,\n",
    "                            load_if_exists=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:17:14,162]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_00_04_linex_26-07-2023_03-45-45' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,261]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_00_04_linlin_19-07-2023_22-26-38' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,418]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_00_04_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,526]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_00_04_wrmse_26-07-2023_18-03-52\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,625]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_04_08_linex_26-07-2023_04-43-10' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,718]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_04_08_linlin_20-07-2023_05-57-00' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,810]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_04_08_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,912]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_04_08_wrmse_26-07-2023_18-42-01\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:14,995]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_08_12_linex_26-07-2023_05-46-18' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,109]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_08_12_linlin_20-07-2023_06-47-58' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,222]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_08_12_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,323]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_08_12_wrmse_26-07-2023_19-42-20\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,409]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_12_16_linex_26-07-2023_06-54-21' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,661]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_12_16_linlin_20-07-2023_07-47-42' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:15,923]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_12_16_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,120]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_12_16_wrmse_26-07-2023_20-52-17\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,228]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_16_20_linex_26-07-2023_07-48-00' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,329]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_16_20_linlin_20-07-2023_08-50-57' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,428]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_16_20_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,560]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_16_20_wrmse_26-07-2023_22-03-55\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,661]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_20_24_linex_26-07-2023_08-47-09' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,745]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:16,870]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_20_24_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:17,797]\u001b[0m A new study created in RDB with name: tune_informer_SRL_NEG_20_24_wrmse_26-07-2023_22-55-30\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:17,882]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_00_04_linex_25-07-2023_23-07-22' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:17,976]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_00_04_linlin_19-07-2023_23-39-57' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,100]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_00_04_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,221]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_00_04_wrmse_26-07-2023_13-16-16\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,329]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_04_08_linex_26-07-2023_00-30-13' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,429]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_04_08_linlin_20-07-2023_00-39-36' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,528]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_04_08_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,624]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_04_08_wrmse_26-07-2023_13-25-16\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,693]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_08_12_linex_26-07-2023_01-34-24' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,788]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_08_12_linlin_20-07-2023_01-51-59' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,871]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_08_12_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:18,955]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_08_12_wrmse_26-07-2023_14-15-02\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,023]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_12_16_linex_26-07-2023_01-48-41' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,114]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_12_16_linlin_20-07-2023_03-17-40' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,207]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_12_16_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,290]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_12_16_wrmse_26-07-2023_15-09-54\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,353]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_16_20_linex_26-07-2023_02-46-42' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,423]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_16_20_linlin_20-07-2023_04-08-22' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,511]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_16_20_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,610]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_16_20_wrmse_26-07-2023_15-58-54\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,704]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_20_24_linex_26-07-2023_03-35-45' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,793]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_20_24_linlin_20-07-2023_04-43-35' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:19,973]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_20_24_rmse_26-07-2023_17-08-37\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:20,089]\u001b[0m A new study created in RDB with name: tune_informer_SRL_POS_20_24_wrmse_26-07-2023_17-08-37\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "s = Studies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEG_00_04_linex': <optuna.study.study.Study at 0x21e9d78f010>,\n",
       " 'NEG_00_04_linlin': <optuna.study.study.Study at 0x21e9a6d1750>,\n",
       " 'NEG_00_04_rmse.db': <optuna.study.study.Study at 0x21e9cd17be0>,\n",
       " 'NEG_00_04_w': <optuna.study.study.Study at 0x21e9d274190>,\n",
       " 'NEG_04_08_linex': <optuna.study.study.Study at 0x21e9d762e30>,\n",
       " 'NEG_04_08_linlin': <optuna.study.study.Study at 0x21e9ccb7bb0>,\n",
       " 'NEG_04_08_rmse.db': <optuna.study.study.Study at 0x21e9cd35660>,\n",
       " 'NEG_04_08_w': <optuna.study.study.Study at 0x21e9cf270d0>,\n",
       " 'NEG_08_12_linex': <optuna.study.study.Study at 0x21e9cea1c60>,\n",
       " 'NEG_08_12_linlin': <optuna.study.study.Study at 0x21e9d51f760>,\n",
       " 'NEG_08_12_rmse.db': <optuna.study.study.Study at 0x21e9d4a3220>,\n",
       " 'NEG_08_12_w': <optuna.study.study.Study at 0x21e9cfab880>,\n",
       " 'NEG_12_16_linex': <optuna.study.study.Study at 0x21e9d7a7730>,\n",
       " 'NEG_12_16_linlin': <optuna.study.study.Study at 0x21e9d6eebf0>,\n",
       " 'NEG_12_16_rmse.db': <optuna.study.study.Study at 0x21e9d6ec220>,\n",
       " 'NEG_12_16_w': <optuna.study.study.Study at 0x21e9d647b20>,\n",
       " 'NEG_16_20_linex': <optuna.study.study.Study at 0x21e9d817af0>,\n",
       " 'NEG_16_20_linlin': <optuna.study.study.Study at 0x21e9d911270>,\n",
       " 'NEG_16_20_rmse.db': <optuna.study.study.Study at 0x21e9d6d51b0>,\n",
       " 'NEG_16_20_w': <optuna.study.study.Study at 0x21e9d816890>,\n",
       " 'NEG_20_24_linex': <optuna.study.study.Study at 0x21e9d8b9660>,\n",
       " 'NEG_20_24_linlin': <optuna.study.study.Study at 0x21e9d54da80>,\n",
       " 'NEG_20_24_rmse.db': <optuna.study.study.Study at 0x21e9d96ac80>,\n",
       " 'NEG_20_24_w': <optuna.study.study.Study at 0x21e9d6d6230>,\n",
       " 'POS_00_04_linex': <optuna.study.study.Study at 0x21e9d9111b0>,\n",
       " 'POS_00_04_linlin': <optuna.study.study.Study at 0x21e9d990b20>,\n",
       " 'POS_00_04_rmse.db': <optuna.study.study.Study at 0x21e9d990460>,\n",
       " 'POS_00_04_w': <optuna.study.study.Study at 0x21e9d9860b0>,\n",
       " 'POS_04_08_linex': <optuna.study.study.Study at 0x21e9da29ae0>,\n",
       " 'POS_04_08_linlin': <optuna.study.study.Study at 0x21e9cc67f10>,\n",
       " 'POS_04_08_rmse.db': <optuna.study.study.Study at 0x21e9d73aad0>,\n",
       " 'POS_04_08_w': <optuna.study.study.Study at 0x21e9cea07c0>,\n",
       " 'POS_08_12_linex': <optuna.study.study.Study at 0x21e9b6bb7f0>,\n",
       " 'POS_08_12_linlin': <optuna.study.study.Study at 0x21e9d13d000>,\n",
       " 'POS_08_12_rmse.db': <optuna.study.study.Study at 0x21e9d0bf070>,\n",
       " 'POS_08_12_w': <optuna.study.study.Study at 0x21e9cda1540>,\n",
       " 'POS_12_16_linex': <optuna.study.study.Study at 0x21e9d776380>,\n",
       " 'POS_12_16_linlin': <optuna.study.study.Study at 0x21e9ce1aa70>,\n",
       " 'POS_12_16_rmse.db': <optuna.study.study.Study at 0x21e9da70f10>,\n",
       " 'POS_12_16_w': <optuna.study.study.Study at 0x21e9d4a19f0>,\n",
       " 'POS_16_20_linex': <optuna.study.study.Study at 0x21e9d984520>,\n",
       " 'POS_16_20_linlin': <optuna.study.study.Study at 0x21e9d96b640>,\n",
       " 'POS_16_20_rmse.db': <optuna.study.study.Study at 0x21e9da4a980>,\n",
       " 'POS_16_20_w': <optuna.study.study.Study at 0x21e9d0c62f0>,\n",
       " 'POS_20_24_linex': <optuna.study.study.Study at 0x21e9da4b100>,\n",
       " 'POS_20_24_linlin': <optuna.study.study.Study at 0x21e9da4ace0>,\n",
       " 'POS_20_24_rmse.db': <optuna.study.study.Study at 0x21e9d9d11e0>,\n",
       " 'POS_20_24_w': <optuna.study.study.Study at 0x21e9d50ea70>}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>values_0</th>\n",
       "      <th>values_1</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_d_layers</th>\n",
       "      <th>params_d_model</th>\n",
       "      <th>params_e_layers</th>\n",
       "      <th>params_label_seq_len_ratio</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_linlin_weight</th>\n",
       "      <th>params_n_heads</th>\n",
       "      <th>params_seq_len</th>\n",
       "      <th>params_train_epochs</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>1871.47</td>\n",
       "      <td>2023-07-20 04:58:52.745642</td>\n",
       "      <td>2023-07-20 04:59:44.421885</td>\n",
       "      <td>0 days 00:00:51.676243</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.195</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>1834.47</td>\n",
       "      <td>2023-07-20 05:01:46.550948</td>\n",
       "      <td>2023-07-20 05:02:53.832049</td>\n",
       "      <td>0 days 00:01:07.281101</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.180</td>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>1819.90</td>\n",
       "      <td>2023-07-20 05:08:01.541279</td>\n",
       "      <td>2023-07-20 05:08:40.884875</td>\n",
       "      <td>0 days 00:00:39.343596</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.225</td>\n",
       "      <td>12</td>\n",
       "      <td>98</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>1817.32</td>\n",
       "      <td>2023-07-20 04:54:11.313733</td>\n",
       "      <td>2023-07-20 04:55:23.825876</td>\n",
       "      <td>0 days 00:01:12.512143</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>896</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.160</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>1792.78</td>\n",
       "      <td>2023-07-20 05:00:56.743870</td>\n",
       "      <td>2023-07-20 05:01:46.504070</td>\n",
       "      <td>0 days 00:00:49.760200</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.185</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>1790.59</td>\n",
       "      <td>2023-07-20 05:50:22.735464</td>\n",
       "      <td>2023-07-20 05:51:41.484877</td>\n",
       "      <td>0 days 00:01:18.749413</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.135</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>1788.65</td>\n",
       "      <td>2023-07-20 05:11:53.259930</td>\n",
       "      <td>2023-07-20 05:12:43.064695</td>\n",
       "      <td>0 days 00:00:49.804765</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.195</td>\n",
       "      <td>12</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>1774.63</td>\n",
       "      <td>2023-07-20 05:00:15.678036</td>\n",
       "      <td>2023-07-20 05:00:56.721875</td>\n",
       "      <td>0 days 00:00:41.043839</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.270</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>1766.75</td>\n",
       "      <td>2023-07-20 04:46:05.753925</td>\n",
       "      <td>2023-07-20 04:47:12.932637</td>\n",
       "      <td>0 days 00:01:07.178712</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>896</td>\n",
       "      <td>4</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.250</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>1750.11</td>\n",
       "      <td>2023-07-20 05:32:05.671768</td>\n",
       "      <td>2023-07-20 05:32:53.682790</td>\n",
       "      <td>0 days 00:00:48.011022</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.295</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number  values_0  values_1             datetime_start  \\\n",
       "19      19  0.008273   1871.47 2023-07-20 04:58:52.745642   \n",
       "23      23  0.008748   1834.47 2023-07-20 05:01:46.550948   \n",
       "36      36  0.010615   1819.90 2023-07-20 05:08:01.541279   \n",
       "15      15  0.007802   1817.32 2023-07-20 04:54:11.313733   \n",
       "22      22  0.008341   1792.78 2023-07-20 05:00:56.743870   \n",
       "93      93  0.006592   1790.59 2023-07-20 05:50:22.735464   \n",
       "43      43  0.009442   1788.65 2023-07-20 05:11:53.259930   \n",
       "21      21  0.008630   1774.63 2023-07-20 05:00:15.678036   \n",
       "4        4  0.010600   1766.75 2023-07-20 04:46:05.753925   \n",
       "68      68  0.011477   1750.11 2023-07-20 05:32:05.671768   \n",
       "\n",
       "            datetime_complete               duration  params_batch_size  \\\n",
       "19 2023-07-20 04:59:44.421885 0 days 00:00:51.676243                  8   \n",
       "23 2023-07-20 05:02:53.832049 0 days 00:01:07.281101                  8   \n",
       "36 2023-07-20 05:08:40.884875 0 days 00:00:39.343596                  8   \n",
       "15 2023-07-20 04:55:23.825876 0 days 00:01:12.512143                  8   \n",
       "22 2023-07-20 05:01:46.504070 0 days 00:00:49.760200                  8   \n",
       "93 2023-07-20 05:51:41.484877 0 days 00:01:18.749413                  8   \n",
       "43 2023-07-20 05:12:43.064695 0 days 00:00:49.804765                  8   \n",
       "21 2023-07-20 05:00:56.721875 0 days 00:00:41.043839                  8   \n",
       "4  2023-07-20 04:47:12.932637 0 days 00:01:07.178712                  8   \n",
       "68 2023-07-20 05:32:53.682790 0 days 00:00:48.011022                 16   \n",
       "\n",
       "    params_d_layers  params_d_model  params_e_layers  \\\n",
       "19                1             512                5   \n",
       "23                2             512                6   \n",
       "36                1             512                3   \n",
       "15                2             896                5   \n",
       "22                1             384                5   \n",
       "93                4             128                5   \n",
       "43                1             512                4   \n",
       "21                1             384                5   \n",
       "4                 3             896                4   \n",
       "68                1             768                5   \n",
       "\n",
       "    params_label_seq_len_ratio  params_learning_rate  params_linlin_weight  \\\n",
       "19                       0.450              0.000033                 0.195   \n",
       "23                       0.400              0.000120                 0.180   \n",
       "36                       0.525              0.000100                 0.225   \n",
       "15                       0.400              0.000119                 0.160   \n",
       "22                       0.450              0.000136                 0.185   \n",
       "93                       0.625              0.000162                 0.135   \n",
       "43                       0.450              0.000357                 0.195   \n",
       "21                       0.450              0.000216                 0.270   \n",
       "4                        0.550              0.000274                 0.250   \n",
       "68                       0.400              0.000142                 0.295   \n",
       "\n",
       "    params_n_heads  params_seq_len  params_train_epochs     state  \n",
       "19               4             112                   12  COMPLETE  \n",
       "23               8              91                   13  COMPLETE  \n",
       "36              12              98                   13  COMPLETE  \n",
       "15               4              84                   11  COMPLETE  \n",
       "22               4             105                   12  COMPLETE  \n",
       "93               4             105                   12  COMPLETE  \n",
       "43              12             105                   12  COMPLETE  \n",
       "21               4             105                   12  COMPLETE  \n",
       "4                4              77                    9  COMPLETE  \n",
       "68              28              70                   13  COMPLETE  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st1 = st['POS_20_24_linlin']\n",
    "st1.trials_dataframe().nlargest(10, 'values_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>values_0</th>\n",
       "      <th>values_1</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_d_layers</th>\n",
       "      <th>params_d_model</th>\n",
       "      <th>params_e_layers</th>\n",
       "      <th>params_label_seq_len_ratio</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_linlin_weight</th>\n",
       "      <th>params_n_heads</th>\n",
       "      <th>params_seq_len</th>\n",
       "      <th>params_train_epochs</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>474.27</td>\n",
       "      <td>2023-07-20 10:17:12.052383</td>\n",
       "      <td>2023-07-20 10:17:47.146595</td>\n",
       "      <td>0 days 00:00:35.094212</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>768</td>\n",
       "      <td>7</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.450</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>434.02</td>\n",
       "      <td>2023-07-20 10:09:39.766908</td>\n",
       "      <td>2023-07-20 10:10:10.179617</td>\n",
       "      <td>0 days 00:00:30.412709</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.435</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>13</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>422.29</td>\n",
       "      <td>2023-07-20 10:15:10.193020</td>\n",
       "      <td>2023-07-20 10:15:29.769619</td>\n",
       "      <td>0 days 00:00:19.576599</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>2</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.345</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.032716</td>\n",
       "      <td>346.44</td>\n",
       "      <td>2023-07-20 10:13:04.290060</td>\n",
       "      <td>2023-07-20 10:13:31.828943</td>\n",
       "      <td>0 days 00:00:27.538883</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.420</td>\n",
       "      <td>32</td>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.037866</td>\n",
       "      <td>340.15</td>\n",
       "      <td>2023-07-20 10:10:25.414069</td>\n",
       "      <td>2023-07-20 10:10:50.412062</td>\n",
       "      <td>0 days 00:00:24.997993</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.425</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>306.46</td>\n",
       "      <td>2023-07-20 10:19:49.336438</td>\n",
       "      <td>2023-07-20 10:20:08.293044</td>\n",
       "      <td>0 days 00:00:18.956606</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>384</td>\n",
       "      <td>6</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.032030</td>\n",
       "      <td>0.275</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>267.88</td>\n",
       "      <td>2023-07-20 10:19:16.893232</td>\n",
       "      <td>2023-07-20 10:19:49.298313</td>\n",
       "      <td>0 days 00:00:32.405081</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "      <td>6</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.024807</td>\n",
       "      <td>0.290</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>252.93</td>\n",
       "      <td>2023-07-20 10:21:09.438245</td>\n",
       "      <td>2023-07-20 10:22:13.462938</td>\n",
       "      <td>0 days 00:01:04.024693</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>0.220</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.026248</td>\n",
       "      <td>234.18</td>\n",
       "      <td>2023-07-20 10:15:52.834835</td>\n",
       "      <td>2023-07-20 10:16:17.640322</td>\n",
       "      <td>0 days 00:00:24.805487</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.370</td>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>231.04</td>\n",
       "      <td>2023-07-20 10:18:42.832355</td>\n",
       "      <td>2023-07-20 10:19:16.877604</td>\n",
       "      <td>0 days 00:00:34.045249</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>896</td>\n",
       "      <td>7</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.089015</td>\n",
       "      <td>0.350</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number  values_0  values_1             datetime_start  \\\n",
       "15      15  0.025573    474.27 2023-07-20 10:17:12.052383   \n",
       "1        1  0.025525    434.02 2023-07-20 10:09:39.766908   \n",
       "11      11  0.026828    422.29 2023-07-20 10:15:10.193020   \n",
       "7        7  0.032716    346.44 2023-07-20 10:13:04.290060   \n",
       "3        3  0.037866    340.15 2023-07-20 10:10:25.414069   \n",
       "77      77  0.018187    306.46 2023-07-20 10:19:49.336438   \n",
       "76      76  0.019606    267.88 2023-07-20 10:19:16.893232   \n",
       "91      91  0.015803    252.93 2023-07-20 10:21:09.438245   \n",
       "13      13  0.026248    234.18 2023-07-20 10:15:52.834835   \n",
       "75      75  0.024580    231.04 2023-07-20 10:18:42.832355   \n",
       "\n",
       "            datetime_complete               duration  params_batch_size  \\\n",
       "15 2023-07-20 10:17:47.146595 0 days 00:00:35.094212                 32   \n",
       "1  2023-07-20 10:10:10.179617 0 days 00:00:30.412709                 32   \n",
       "11 2023-07-20 10:15:29.769619 0 days 00:00:19.576599                 32   \n",
       "7  2023-07-20 10:13:31.828943 0 days 00:00:27.538883                 32   \n",
       "3  2023-07-20 10:10:50.412062 0 days 00:00:24.997993                 16   \n",
       "77 2023-07-20 10:20:08.293044 0 days 00:00:18.956606                 24   \n",
       "76 2023-07-20 10:19:49.298313 0 days 00:00:32.405081                 24   \n",
       "91 2023-07-20 10:22:13.462938 0 days 00:01:04.024693                  8   \n",
       "13 2023-07-20 10:16:17.640322 0 days 00:00:24.805487                 32   \n",
       "75 2023-07-20 10:19:16.877604 0 days 00:00:34.045249                 16   \n",
       "\n",
       "    params_d_layers  params_d_model  params_e_layers  \\\n",
       "15                3             768                7   \n",
       "1                 2             768                2   \n",
       "11                1             896                2   \n",
       "7                 2             640                6   \n",
       "3                 2             128                7   \n",
       "77                4             384                6   \n",
       "76                4             640                6   \n",
       "91                4             384                5   \n",
       "13                1             512                3   \n",
       "75                3             896                7   \n",
       "\n",
       "    params_label_seq_len_ratio  params_learning_rate  params_linlin_weight  \\\n",
       "15                       0.400              0.003017                 0.450   \n",
       "1                        0.625              0.001725                 0.435   \n",
       "11                       0.650              0.000016                 0.345   \n",
       "7                        0.750              0.000353                 0.420   \n",
       "3                        0.800              0.000054                 0.425   \n",
       "77                       0.475              0.032030                 0.275   \n",
       "76                       0.475              0.024807                 0.290   \n",
       "91                       0.450              0.034280                 0.220   \n",
       "13                       0.675              0.012969                 0.370   \n",
       "75                       0.400              0.089015                 0.350   \n",
       "\n",
       "    params_n_heads  params_seq_len  params_train_epochs     state  \n",
       "15              16              91                   10  COMPLETE  \n",
       "1               16              91                   13  COMPLETE  \n",
       "11              12              84                   12  COMPLETE  \n",
       "7               32             105                    6  COMPLETE  \n",
       "3               20              98                   14  COMPLETE  \n",
       "77               8              56                   11  COMPLETE  \n",
       "76               8              63                   10  COMPLETE  \n",
       "91               8              63                    9  COMPLETE  \n",
       "13              24              98                   11  COMPLETE  \n",
       "75              24              77                   10  COMPLETE  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st0.trials_dataframe().nlargest(10, 'values_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:14:05,139]\u001b[0m Using an existing study with name 'tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:14:05,231]\u001b[0m Using an existing study with name 'tune_informer_SRL_POS_20_24_linlin_20-07-2023_04-43-35' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "st = s.get_studies(conditions = ['20_24', 'linlin'], mode='and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = st['NEG_20_24_linlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=1, state=TrialState.COMPLETE, values=[0.025525052100419998, 434.02], datetime_start=datetime.datetime(2023, 7, 20, 10, 9, 39, 766908), datetime_complete=datetime.datetime(2023, 7, 20, 10, 10, 10, 179617), params={'batch_size': 32, 'd_layers': 2, 'd_model': 768, 'e_layers': 2, 'label_seq_len_ratio': 0.625, 'learning_rate': 0.001724838423862607, 'linlin_weight': 0.435, 'n_heads': 16, 'seq_len': 91, 'train_epochs': 13}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=2, value=None),\n",
       " FrozenTrial(number=5, state=TrialState.COMPLETE, values=[0.013309326954185963, 57.45], datetime_start=datetime.datetime(2023, 7, 20, 10, 11, 57, 646939), datetime_complete=datetime.datetime(2023, 7, 20, 10, 12, 20, 869168), params={'batch_size': 24, 'd_layers': 4, 'd_model': 512, 'e_layers': 5, 'label_seq_len_ratio': 0.5, 'learning_rate': 0.0012904711664256537, 'linlin_weight': 0.165, 'n_heads': 16, 'seq_len': 56, 'train_epochs': 7}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=6, value=None),\n",
       " FrozenTrial(number=8, state=TrialState.COMPLETE, values=[0.007988754659891129, 0.0], datetime_start=datetime.datetime(2023, 7, 20, 10, 13, 31, 854604), datetime_complete=datetime.datetime(2023, 7, 20, 10, 14, 8, 752712), params={'batch_size': 16, 'd_layers': 4, 'd_model': 384, 'e_layers': 6, 'label_seq_len_ratio': 0.625, 'learning_rate': 0.006387447808759686, 'linlin_weight': 0.085, 'n_heads': 32, 'seq_len': 91, 'train_epochs': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=9, value=None),\n",
       " FrozenTrial(number=15, state=TrialState.COMPLETE, values=[0.025572990998625755, 474.27], datetime_start=datetime.datetime(2023, 7, 20, 10, 17, 12, 52383), datetime_complete=datetime.datetime(2023, 7, 20, 10, 17, 47, 146595), params={'batch_size': 32, 'd_layers': 3, 'd_model': 768, 'e_layers': 7, 'label_seq_len_ratio': 0.4, 'learning_rate': 0.003016893138708723, 'linlin_weight': 0.45, 'n_heads': 16, 'seq_len': 91, 'train_epochs': 10}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=16, value=None),\n",
       " FrozenTrial(number=77, state=TrialState.COMPLETE, values=[0.01818719506263733, 306.46], datetime_start=datetime.datetime(2023, 7, 20, 10, 19, 49, 336438), datetime_complete=datetime.datetime(2023, 7, 20, 10, 20, 8, 293044), params={'batch_size': 24, 'd_layers': 4, 'd_model': 384, 'e_layers': 6, 'label_seq_len_ratio': 0.47500000000000003, 'learning_rate': 0.03202965715291913, 'linlin_weight': 0.275, 'n_heads': 8, 'seq_len': 56, 'train_epochs': 11}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=78, value=None),\n",
       " FrozenTrial(number=90, state=TrialState.COMPLETE, values=[0.011194058693945408, 17.92], datetime_start=datetime.datetime(2023, 7, 20, 10, 20, 40, 605347), datetime_complete=datetime.datetime(2023, 7, 20, 10, 21, 9, 422617), params={'batch_size': 16, 'd_layers': 3, 'd_model': 128, 'e_layers': 6, 'label_seq_len_ratio': 0.525, 'learning_rate': 0.007955786410145167, 'linlin_weight': 0.135, 'n_heads': 16, 'seq_len': 56, 'train_epochs': 11}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=91, value=None),\n",
       " FrozenTrial(number=91, state=TrialState.COMPLETE, values=[0.015802673995494843, 252.93], datetime_start=datetime.datetime(2023, 7, 20, 10, 21, 9, 438245), datetime_complete=datetime.datetime(2023, 7, 20, 10, 22, 13, 462938), params={'batch_size': 8, 'd_layers': 4, 'd_model': 384, 'e_layers': 5, 'label_seq_len_ratio': 0.45, 'learning_rate': 0.034280391438396826, 'linlin_weight': 0.22000000000000003, 'n_heads': 8, 'seq_len': 63, 'train_epochs': 9}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=32, log=False, low=8, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=1024, log=False, low=128, step=128), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'linlin_weight': FloatDistribution(high=0.45, log=False, low=0.05, step=0.005), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=56, step=7), 'train_epochs': IntDistribution(high=14, log=False, low=6, step=1)}, trial_id=92, value=None)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st0.best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEG_20_24_linlin'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'_'.join('tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51.db'.split('_')[3:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51.db', 'tune_informer_SRL_POS_20_24_linlin_20-07-2023_04-43-35.db'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tune_informer_SRL_NEG_20_24_linex_26-07-2023_08-47-09.db': <optuna.study.study.Study at 0x2296068f220>,\n",
       " 'tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51.db': <optuna.study.study.Study at 0x229607d7250>,\n",
       " 'tune_informer_SRL_NEG_20_24_rmse.db': <optuna.study.study.Study at 0x2296080f4c0>,\n",
       " 'tune_informer_SRL_NEG_20_24_w_rmse_26-07-2023_22-55-30.db': <optuna.study.study.Study at 0x229607d7580>,\n",
       " 'tune_informer_SRL_POS_20_24_linex_26-07-2023_03-35-45.db': <optuna.study.study.Study at 0x229608a20e0>,\n",
       " 'tune_informer_SRL_POS_20_24_linlin_20-07-2023_04-43-35.db': <optuna.study.study.Study at 0x22960814b20>,\n",
       " 'tune_informer_SRL_POS_20_24_rmse.db': <optuna.study.study.Study at 0x229609cefe0>,\n",
       " 'tune_informer_SRL_POS_20_24_w_rmse_26-07-2023_17-08-37.db': <optuna.study.study.Study at 0x229607d91b0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = s.studies['tune_informer_SRL_NEG_20_24_rmse.db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, state=TrialState.COMPLETE, values=[0.01948489248752594, 398.54], datetime_start=datetime.datetime(2023, 7, 18, 12, 25, 44, 609874), datetime_complete=datetime.datetime(2023, 7, 18, 12, 26, 17, 920934), params={'batch_size': 64, 'd_layers': 2, 'd_model': 1536, 'e_layers': 4, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 5.2611266367224943e-05, 'n_heads': 4, 'seq_len': 77, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=1, value=None),\n",
       " FrozenTrial(number=1, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 26, 17, 952208), datetime_complete=datetime.datetime(2023, 7, 18, 12, 26, 19, 652563), params={'batch_size': 16, 'd_layers': 1, 'd_model': 1024, 'e_layers': 7, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.025303486029728955, 'n_heads': 24, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=2, value=None),\n",
       " FrozenTrial(number=2, state=TrialState.COMPLETE, values=[0.022035526111721992, 302.88], datetime_start=datetime.datetime(2023, 7, 18, 12, 26, 19, 717502), datetime_complete=datetime.datetime(2023, 7, 18, 12, 26, 40, 230509), params={'batch_size': 48, 'd_layers': 2, 'd_model': 1024, 'e_layers': 4, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.00018427619934617597, 'n_heads': 4, 'seq_len': 98, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=3, value=None),\n",
       " FrozenTrial(number=3, state=TrialState.COMPLETE, values=[3.3385016918182373, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 26, 40, 240566), datetime_complete=datetime.datetime(2023, 7, 18, 12, 27, 17, 483847), params={'batch_size': 64, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.0025013449352438476, 'n_heads': 20, 'seq_len': 77, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=4, value=None),\n",
       " FrozenTrial(number=4, state=TrialState.COMPLETE, values=[0.012381029315292835, 305.3], datetime_start=datetime.datetime(2023, 7, 18, 12, 27, 17, 491883), datetime_complete=datetime.datetime(2023, 7, 18, 12, 27, 41, 268999), params={'batch_size': 16, 'd_layers': 2, 'd_model': 1280, 'e_layers': 2, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.08844908029804724, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=5, value=None),\n",
       " FrozenTrial(number=5, state=TrialState.COMPLETE, values=[0.015499475412070751, 279.68], datetime_start=datetime.datetime(2023, 7, 18, 12, 27, 41, 284625), datetime_complete=datetime.datetime(2023, 7, 18, 12, 28, 33, 596936), params={'batch_size': 40, 'd_layers': 3, 'd_model': 1024, 'e_layers': 5, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.0001448954234929495, 'n_heads': 12, 'seq_len': 112, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=6, value=None),\n",
       " FrozenTrial(number=6, state=TrialState.COMPLETE, values=[0.2504409849643707, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 28, 33, 612559), datetime_complete=datetime.datetime(2023, 7, 18, 12, 29, 14, 344694), params={'batch_size': 32, 'd_layers': 3, 'd_model': 2048, 'e_layers': 3, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.008536922629164228, 'n_heads': 24, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=7, value=None),\n",
       " FrozenTrial(number=7, state=TrialState.COMPLETE, values=[0.020544106140732765, 228.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 29, 14, 363691), datetime_complete=datetime.datetime(2023, 7, 18, 12, 30, 26, 858324), params={'batch_size': 56, 'd_layers': 3, 'd_model': 1280, 'e_layers': 6, 'label_seq_len_ratio': 0.675, 'learning_rate': 0.00027148867215202063, 'n_heads': 32, 'seq_len': 98, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=8, value=None),\n",
       " FrozenTrial(number=8, state=TrialState.COMPLETE, values=[14.098302841186523, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 30, 26, 873948), datetime_complete=datetime.datetime(2023, 7, 18, 12, 31, 10, 880335), params={'batch_size': 40, 'd_layers': 1, 'd_model': 1792, 'e_layers': 4, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.06299893720521, 'n_heads': 4, 'seq_len': 91, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=9, value=None),\n",
       " FrozenTrial(number=9, state=TrialState.COMPLETE, values=[0.010457801632583141, 488.05], datetime_start=datetime.datetime(2023, 7, 18, 12, 31, 10, 911608), datetime_complete=datetime.datetime(2023, 7, 18, 12, 32, 24, 651149), params={'batch_size': 64, 'd_layers': 4, 'd_model': 1792, 'e_layers': 3, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.0030998168209775082, 'n_heads': 28, 'seq_len': 77, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=10, value=None),\n",
       " FrozenTrial(number=10, state=TrialState.COMPLETE, values=[0.008492290042340755, 491.56], datetime_start=datetime.datetime(2023, 7, 18, 12, 32, 24, 698023), datetime_complete=datetime.datetime(2023, 7, 18, 12, 33, 3, 947663), params={'batch_size': 48, 'd_layers': 2, 'd_model': 1536, 'e_layers': 4, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.003910441271775587, 'n_heads': 12, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=11, value=None),\n",
       " FrozenTrial(number=11, state=TrialState.COMPLETE, values=[0.03964661434292793, 73.36], datetime_start=datetime.datetime(2023, 7, 18, 12, 33, 3, 978882), datetime_complete=datetime.datetime(2023, 7, 18, 12, 34, 6, 67981), params={'batch_size': 24, 'd_layers': 1, 'd_model': 2048, 'e_layers': 6, 'label_seq_len_ratio': 0.4, 'learning_rate': 1.9988173559615335e-05, 'n_heads': 12, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=12, value=None),\n",
       " FrozenTrial(number=12, state=TrialState.COMPLETE, values=[0.041350897401571274, 173.22], datetime_start=datetime.datetime(2023, 7, 18, 12, 34, 6, 77989), datetime_complete=datetime.datetime(2023, 7, 18, 12, 35, 12, 739966), params={'batch_size': 48, 'd_layers': 4, 'd_model': 1792, 'e_layers': 2, 'label_seq_len_ratio': 0.8, 'learning_rate': 0.001651588708663243, 'n_heads': 12, 'seq_len': 63, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=13, value=None),\n",
       " FrozenTrial(number=13, state=TrialState.COMPLETE, values=[0.02164275012910366, 34.27], datetime_start=datetime.datetime(2023, 7, 18, 12, 35, 12, 771212), datetime_complete=datetime.datetime(2023, 7, 18, 12, 35, 53, 152542), params={'batch_size': 48, 'd_layers': 1, 'd_model': 1792, 'e_layers': 3, 'label_seq_len_ratio': 0.8, 'learning_rate': 0.008256007940682375, 'n_heads': 16, 'seq_len': 63, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=14, value=None),\n",
       " FrozenTrial(number=14, state=TrialState.COMPLETE, values=[0.06600560992956161, 167.97], datetime_start=datetime.datetime(2023, 7, 18, 12, 35, 53, 170576), datetime_complete=datetime.datetime(2023, 7, 18, 12, 36, 36, 596093), params={'batch_size': 32, 'd_layers': 4, 'd_model': 1280, 'e_layers': 5, 'label_seq_len_ratio': 0.625, 'learning_rate': 0.0007080871801302889, 'n_heads': 28, 'seq_len': 56, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=15, value=None),\n",
       " FrozenTrial(number=15, state=TrialState.COMPLETE, values=[0.27557218074798584, 78.15], datetime_start=datetime.datetime(2023, 7, 18, 12, 36, 36, 611719), datetime_complete=datetime.datetime(2023, 7, 18, 12, 37, 10, 333026), params={'batch_size': 56, 'd_layers': 2, 'd_model': 1536, 'e_layers': 3, 'label_seq_len_ratio': 0.47500000000000003, 'learning_rate': 0.0070743302852704125, 'n_heads': 16, 'seq_len': 77, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=16, value=None),\n",
       " FrozenTrial(number=16, state=TrialState.COMPLETE, values=[0.035058483481407166, 226.87], datetime_start=datetime.datetime(2023, 7, 18, 12, 37, 10, 348656), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 13, 803259), params={'batch_size': 32, 'd_layers': 2, 'd_model': 1792, 'e_layers': 5, 'label_seq_len_ratio': 0.625, 'learning_rate': 1.1920608666513185e-05, 'n_heads': 8, 'seq_len': 70, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=17, value=None),\n",
       " FrozenTrial(number=17, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 13, 834518), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 15, 348035), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.02435301485457026, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=18, value=None),\n",
       " FrozenTrial(number=18, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 15, 366086), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 17, 90545), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.023211443220808963, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=19, value=None),\n",
       " FrozenTrial(number=19, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 17, 121805), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 18, 786534), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.0006869779295118574, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=20, value=None),\n",
       " FrozenTrial(number=20, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 18, 804588), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 20, 294852), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.0006136210360867578, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=21, value=None),\n",
       " FrozenTrial(number=21, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 20, 312967), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 22, 22351), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.0006849995024463776, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=22, value=None),\n",
       " FrozenTrial(number=22, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 22, 32406), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 23, 703733), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.525, 'learning_rate': 0.027223523074638482, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=23, value=None),\n",
       " FrozenTrial(number=23, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 23, 721772), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 25, 229616), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.525, 'learning_rate': 0.0006613620757038452, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=24, value=None),\n",
       " FrozenTrial(number=24, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 25, 249691), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 26, 880218), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.0007016972247208261, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=25, value=None),\n",
       " FrozenTrial(number=25, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 26, 898277), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 28, 517145), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.0006279805114541554, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=26, value=None),\n",
       " FrozenTrial(number=26, state=TrialState.COMPLETE, values=[0.015650413930416107, 306.76], datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 28, 527206), datetime_complete=datetime.datetime(2023, 7, 18, 12, 38, 56, 206813), params={'batch_size': 56, 'd_layers': 1, 'd_model': 1280, 'e_layers': 6, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.023383706269409662, 'n_heads': 20, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=27, value=None),\n",
       " FrozenTrial(number=27, state=TrialState.COMPLETE, values=[0.06518104672431946, 168.52], datetime_start=datetime.datetime(2023, 7, 18, 12, 38, 56, 224864), datetime_complete=datetime.datetime(2023, 7, 18, 12, 40, 6, 726967), params={'batch_size': 16, 'd_layers': 4, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.5, 'learning_rate': 0.0006051266509503757, 'n_heads': 8, 'seq_len': 91, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=28, value=None),\n",
       " FrozenTrial(number=28, state=TrialState.COMPLETE, values=[0.06835587322711945, 171.14], datetime_start=datetime.datetime(2023, 7, 18, 12, 40, 6, 745012), datetime_complete=datetime.datetime(2023, 7, 18, 12, 40, 46, 184154), params={'batch_size': 40, 'd_layers': 2, 'd_model': 1536, 'e_layers': 3, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0027393689088442766, 'n_heads': 24, 'seq_len': 49, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=29, value=None),\n",
       " FrozenTrial(number=29, state=TrialState.COMPLETE, values=[0.018738018348813057, 289.93], datetime_start=datetime.datetime(2023, 7, 18, 12, 40, 46, 194163), datetime_complete=datetime.datetime(2023, 7, 18, 12, 42, 19, 67877), params={'batch_size': 24, 'd_layers': 3, 'd_model': 2048, 'e_layers': 4, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.025473929859869585, 'n_heads': 8, 'seq_len': 70, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=30, value=None),\n",
       " FrozenTrial(number=30, state=TrialState.COMPLETE, values=[0.00890724640339613, 461.16], datetime_start=datetime.datetime(2023, 7, 18, 12, 42, 19, 99135), datetime_complete=datetime.datetime(2023, 7, 18, 12, 42, 36, 308897), params={'batch_size': 48, 'd_layers': 1, 'd_model': 1024, 'e_layers': 2, 'label_seq_len_ratio': 0.42500000000000004, 'learning_rate': 0.0011634496953390914, 'n_heads': 16, 'seq_len': 112, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=31, value=None),\n",
       " FrozenTrial(number=31, state=TrialState.COMPLETE, values=[0.03313085064291954, 3.96], datetime_start=datetime.datetime(2023, 7, 18, 12, 42, 36, 334548), datetime_complete=datetime.datetime(2023, 7, 18, 12, 42, 59, 219620), params={'batch_size': 48, 'd_layers': 1, 'd_model': 1024, 'e_layers': 5, 'label_seq_len_ratio': 0.4, 'learning_rate': 0.0008810353503136404, 'n_heads': 16, 'seq_len': 112, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=32, value=None),\n",
       " FrozenTrial(number=32, state=TrialState.COMPLETE, values=[0.600641667842865, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 42, 59, 235246), datetime_complete=datetime.datetime(2023, 7, 18, 12, 43, 57, 83540), params={'batch_size': 56, 'd_layers': 2, 'd_model': 1792, 'e_layers': 4, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.0025865920766810248, 'n_heads': 12, 'seq_len': 84, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=33, value=None),\n",
       " FrozenTrial(number=33, state=TrialState.COMPLETE, values=[0.009924243204295635, 422.6], datetime_start=datetime.datetime(2023, 7, 18, 12, 43, 57, 101599), datetime_complete=datetime.datetime(2023, 7, 18, 12, 44, 40, 471434), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1280, 'e_layers': 3, 'label_seq_len_ratio': 0.675, 'learning_rate': 0.00040647126586286877, 'n_heads': 32, 'seq_len': 56, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=34, value=None),\n",
       " FrozenTrial(number=34, state=TrialState.COMPLETE, values=[0.020006531849503517, 295.2], datetime_start=datetime.datetime(2023, 7, 18, 12, 44, 40, 487061), datetime_complete=datetime.datetime(2023, 7, 18, 12, 44, 55, 915046), params={'batch_size': 64, 'd_layers': 1, 'd_model': 1024, 'e_layers': 2, 'label_seq_len_ratio': 0.45, 'learning_rate': 0.0010670374112869544, 'n_heads': 8, 'seq_len': 70, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=35, value=None),\n",
       " FrozenTrial(number=35, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 44, 55, 961941), datetime_complete=datetime.datetime(2023, 7, 18, 12, 46, 27, 413110), params={'batch_size': 40, 'd_layers': 4, 'd_model': 2048, 'e_layers': 4, 'label_seq_len_ratio': 0.6000000000000001, 'learning_rate': 5.637771895941962e-05, 'n_heads': 20, 'seq_len': 105, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=36, value=None),\n",
       " FrozenTrial(number=36, state=TrialState.COMPLETE, values=[0.013860246166586876, 315.92], datetime_start=datetime.datetime(2023, 7, 18, 12, 46, 27, 431238), datetime_complete=datetime.datetime(2023, 7, 18, 12, 47, 31, 384481), params={'batch_size': 40, 'd_layers': 4, 'd_model': 2048, 'e_layers': 4, 'label_seq_len_ratio': 0.6000000000000001, 'learning_rate': 0.0046063037647170344, 'n_heads': 20, 'seq_len': 56, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=37, value=None),\n",
       " FrozenTrial(number=37, state=TrialState.COMPLETE, values=[0.02488047070801258, 251.62], datetime_start=datetime.datetime(2023, 7, 18, 12, 47, 31, 400105), datetime_complete=datetime.datetime(2023, 7, 18, 12, 48, 34, 333042), params={'batch_size': 56, 'd_layers': 2, 'd_model': 1792, 'e_layers': 5, 'label_seq_len_ratio': 0.525, 'learning_rate': 7.885690076700046e-05, 'n_heads': 16, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=38, value=None),\n",
       " FrozenTrial(number=38, state=TrialState.COMPLETE, values=[0.07211733609437943, 234.66], datetime_start=datetime.datetime(2023, 7, 18, 12, 48, 34, 348667), datetime_complete=datetime.datetime(2023, 7, 18, 12, 49, 32, 52544), params={'batch_size': 24, 'd_layers': 3, 'd_model': 1280, 'e_layers': 6, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0012167596619275841, 'n_heads': 24, 'seq_len': 84, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=39, value=None),\n",
       " FrozenTrial(number=39, state=TrialState.COMPLETE, values=[0.5006406903266907, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 49, 32, 70590), datetime_complete=datetime.datetime(2023, 7, 18, 12, 49, 58, 156103), params={'batch_size': 48, 'd_layers': 2, 'd_model': 1024, 'e_layers': 3, 'label_seq_len_ratio': 0.675, 'learning_rate': 0.015304485931546104, 'n_heads': 12, 'seq_len': 105, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=40, value=None),\n",
       " FrozenTrial(number=40, state=TrialState.COMPLETE, values=[0.09096193313598633, 65.57], datetime_start=datetime.datetime(2023, 7, 18, 12, 49, 58, 164140), datetime_complete=datetime.datetime(2023, 7, 18, 12, 50, 23, 831878), params={'batch_size': 64, 'd_layers': 1, 'd_model': 1536, 'e_layers': 4, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 3.9129198038676215e-05, 'n_heads': 28, 'seq_len': 70, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=41, value=None),\n",
       " FrozenTrial(number=41, state=TrialState.COMPLETE, values=[0.030157599598169327, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 50, 23, 841939), datetime_complete=datetime.datetime(2023, 7, 18, 12, 51, 46, 781809), params={'batch_size': 40, 'd_layers': 2, 'd_model': 2048, 'e_layers': 5, 'label_seq_len_ratio': 0.6000000000000001, 'learning_rate': 0.004982783224714452, 'n_heads': 8, 'seq_len': 84, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=42, value=None),\n",
       " FrozenTrial(number=42, state=TrialState.COMPLETE, values=[0.07263640314340591, 168.1], datetime_start=datetime.datetime(2023, 7, 18, 12, 51, 46, 797436), datetime_complete=datetime.datetime(2023, 7, 18, 12, 52, 38, 383239), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 3, 'label_seq_len_ratio': 0.675, 'learning_rate': 0.0003778102156653742, 'n_heads': 32, 'seq_len': 56, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=43, value=None),\n",
       " FrozenTrial(number=43, state=TrialState.COMPLETE, values=[0.9761359095573425, 176.58], datetime_start=datetime.datetime(2023, 7, 18, 12, 52, 38, 414491), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 2, 541602), params={'batch_size': 48, 'd_layers': 2, 'd_model': 1280, 'e_layers': 4, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0004517722016520994, 'n_heads': 12, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=44, value=None),\n",
       " FrozenTrial(number=44, state=TrialState.COMPLETE, values=[0.05703101307153702, 187.71], datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 3, 280849), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 33, 896397), params={'batch_size': 32, 'd_layers': 3, 'd_model': 1536, 'e_layers': 4, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 0.00010521240019213119, 'n_heads': 16, 'seq_len': 56, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=45, value=None),\n",
       " FrozenTrial(number=45, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 33, 914444), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 35, 817440), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0017553378755538547, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=46, value=None),\n",
       " FrozenTrial(number=46, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 35, 861184), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 37, 838456), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0016472549782721362, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=47, value=None),\n",
       " FrozenTrial(number=47, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 37, 856497), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 39, 839718), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.00017956725389405056, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=48, value=None),\n",
       " FrozenTrial(number=48, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 39, 857756), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 41, 749110), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0002460823906583618, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=49, value=None),\n",
       " FrozenTrial(number=49, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 41, 774758), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 43, 823244), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.0002710343417867558, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=50, value=None),\n",
       " FrozenTrial(number=50, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 43, 841275), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 45, 864495), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.0017790370661562472, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=51, value=None),\n",
       " FrozenTrial(number=51, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 45, 882531), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 47, 724867), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.00027582528028037155, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=52, value=None),\n",
       " FrozenTrial(number=52, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 47, 744982), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 49, 745181), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0015211865396675542, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=53, value=None),\n",
       " FrozenTrial(number=53, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 49, 763229), datetime_complete=datetime.datetime(2023, 7, 18, 12, 53, 51, 756139), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.00018715179547362638, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=54, value=None),\n",
       " FrozenTrial(number=54, state=TrialState.COMPLETE, values=[0.04552486538887024, 145.4], datetime_start=datetime.datetime(2023, 7, 18, 12, 53, 51, 774233), datetime_complete=datetime.datetime(2023, 7, 18, 12, 54, 43, 30725), params={'batch_size': 56, 'd_layers': 4, 'd_model': 1280, 'e_layers': 4, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.0002456937852036371, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=55, value=None),\n",
       " FrozenTrial(number=55, state=TrialState.COMPLETE, values=[0.06220788136124611, 166.67], datetime_start=datetime.datetime(2023, 7, 18, 12, 54, 43, 48774), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 23, 339725), params={'batch_size': 64, 'd_layers': 2, 'd_model': 1792, 'e_layers': 2, 'label_seq_len_ratio': 0.775, 'learning_rate': 0.0017237219898468318, 'n_heads': 8, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=56, value=None),\n",
       " FrozenTrial(number=56, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 23, 359799), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 25, 635032), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0037663921868779167, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=57, value=None),\n",
       " FrozenTrial(number=57, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 25, 653086), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 27, 716688), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0001753879237186529, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=58, value=None),\n",
       " FrozenTrial(number=58, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 27, 734733), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 30, 38067), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.003452979391096931, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=59, value=None),\n",
       " FrozenTrial(number=59, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 30, 48112), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 32, 363004), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.003647393540464515, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=60, value=None),\n",
       " FrozenTrial(number=60, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 32, 381098), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 34, 494995), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00355542513099535, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=61, value=None),\n",
       " FrozenTrial(number=61, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 34, 513115), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 36, 738464), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0001514437240806244, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=62, value=None),\n",
       " FrozenTrial(number=62, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 36, 756512), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 39, 81425), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 0.003749763545023531, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=63, value=None),\n",
       " FrozenTrial(number=63, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 39, 99471), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 41, 243660), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.003572645890910035, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=64, value=None),\n",
       " FrozenTrial(number=64, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 41, 261707), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 43, 492418), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.003994117778725935, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=65, value=None),\n",
       " FrozenTrial(number=65, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 43, 512484), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 45, 735017), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0032780765395872746, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=66, value=None),\n",
       " FrozenTrial(number=66, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 45, 755098), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 47, 969262), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0041470612523016905, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=67, value=None),\n",
       " FrozenTrial(number=67, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 47, 987311), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 50, 140425), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00015721399868369134, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=68, value=None),\n",
       " FrozenTrial(number=68, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 50, 160568), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 52, 392055), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0035647956238701755, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=69, value=None),\n",
       " FrozenTrial(number=69, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 52, 410095), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 54, 674816), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00018975684097028832, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=70, value=None),\n",
       " FrozenTrial(number=70, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 54, 692853), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 56, 947095), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00016629334747854605, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=71, value=None),\n",
       " FrozenTrial(number=71, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 56, 965142), datetime_complete=datetime.datetime(2023, 7, 18, 12, 55, 59, 48585), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0036470062010695104, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=72, value=None),\n",
       " FrozenTrial(number=72, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 55, 59, 66623), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 1, 379200), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00358151088169896, 'n_heads': 12, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=73, value=None),\n",
       " FrozenTrial(number=73, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 1, 389210), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 3, 623423), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0001755612503653207, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=74, value=None),\n",
       " FrozenTrial(number=74, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 3, 641469), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 5, 865661), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00018575746300364466, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=75, value=None),\n",
       " FrozenTrial(number=75, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 5, 883702), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 8, 28733), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00015785482782483735, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=76, value=None),\n",
       " FrozenTrial(number=76, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 8, 46777), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 10, 292215), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.004163190176705606, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=77, value=None),\n",
       " FrozenTrial(number=77, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 10, 310259), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 12, 615332), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00015467396151349922, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=78, value=None),\n",
       " FrozenTrial(number=78, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 12, 633371), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 14, 838165), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 5.2127227057887104e-05, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=79, value=None),\n",
       " FrozenTrial(number=79, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 14, 856210), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 16, 930665), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0034752989733189232, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=80, value=None),\n",
       " FrozenTrial(number=80, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 16, 948712), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 19, 192726), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.003647918236251231, 'n_heads': 12, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=81, value=None),\n",
       " FrozenTrial(number=81, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 19, 210763), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 21, 445072), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.00017440356273857192, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=82, value=None),\n",
       " FrozenTrial(number=82, state=TrialState.COMPLETE, values=[0.04672699049115181, 97.97], datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 21, 463118), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 45, 86276), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1536, 'e_layers': 3, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.0001699574965455025, 'n_heads': 20, 'seq_len': 49, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=83, value=None),\n",
       " FrozenTrial(number=83, state=TrialState.FAIL, values=None, datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 45, 101902), datetime_complete=datetime.datetime(2023, 7, 18, 12, 56, 46, 771557), params={'batch_size': 40, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.004058342869646944, 'n_heads': 12, 'seq_len': 63, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=84, value=None),\n",
       " FrozenTrial(number=84, state=TrialState.COMPLETE, values=[0.042169228196144104, 173.49], datetime_start=datetime.datetime(2023, 7, 18, 12, 56, 46, 789597), datetime_complete=datetime.datetime(2023, 7, 18, 12, 57, 32, 350387), params={'batch_size': 40, 'd_layers': 1, 'd_model': 1280, 'e_layers': 7, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.0035619011766231438, 'n_heads': 12, 'seq_len': 105, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=85, value=None),\n",
       " FrozenTrial(number=85, state=TrialState.COMPLETE, values=[0.013775575906038284, 2.6], datetime_start=datetime.datetime(2023, 7, 18, 12, 57, 32, 366014), datetime_complete=datetime.datetime(2023, 7, 18, 12, 58, 14, 168471), params={'batch_size': 56, 'd_layers': 3, 'd_model': 1536, 'e_layers': 5, 'label_seq_len_ratio': 0.7250000000000001, 'learning_rate': 0.0016722078771627374, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=86, value=None),\n",
       " FrozenTrial(number=86, state=TrialState.COMPLETE, values=[0.19139359891414642, 0.0], datetime_start=datetime.datetime(2023, 7, 18, 12, 58, 14, 215353), datetime_complete=datetime.datetime(2023, 7, 18, 12, 59, 26, 304520), params={'batch_size': 16, 'd_layers': 2, 'd_model': 1792, 'e_layers': 6, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 0.012049274631201659, 'n_heads': 28, 'seq_len': 49, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=87, value=None),\n",
       " FrozenTrial(number=87, state=TrialState.COMPLETE, values=[0.0665687769651413, 168.93], datetime_start=datetime.datetime(2023, 7, 18, 12, 59, 26, 324652), datetime_complete=datetime.datetime(2023, 7, 18, 12, 59, 53, 175611), params={'batch_size': 40, 'd_layers': 1, 'd_model': 1280, 'e_layers': 3, 'label_seq_len_ratio': 0.45, 'learning_rate': 0.06122013760682299, 'n_heads': 12, 'seq_len': 77, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=88, value=None),\n",
       " FrozenTrial(number=88, state=TrialState.COMPLETE, values=[0.09321005642414093, 97.57], datetime_start=datetime.datetime(2023, 7, 18, 12, 59, 53, 193664), datetime_complete=datetime.datetime(2023, 7, 18, 13, 0, 37, 837053), params={'batch_size': 40, 'd_layers': 4, 'd_model': 1536, 'e_layers': 4, 'label_seq_len_ratio': 0.75, 'learning_rate': 0.004909265065777967, 'n_heads': 16, 'seq_len': 56, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=89, value=None),\n",
       " FrozenTrial(number=89, state=TrialState.COMPLETE, values=[0.010815680027008057, 402.62], datetime_start=datetime.datetime(2023, 7, 18, 13, 0, 37, 852681), datetime_complete=datetime.datetime(2023, 7, 18, 13, 2, 16, 478764), params={'batch_size': 48, 'd_layers': 2, 'd_model': 2048, 'e_layers': 7, 'label_seq_len_ratio': 0.65, 'learning_rate': 0.004469455681190489, 'n_heads': 20, 'seq_len': 98, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=90, value=None),\n",
       " FrozenTrial(number=90, state=TrialState.COMPLETE, values=[0.020489362999796867, 322.18], datetime_start=datetime.datetime(2023, 7, 18, 13, 2, 16, 510022), datetime_complete=datetime.datetime(2023, 7, 18, 13, 2, 40, 357506), params={'batch_size': 48, 'd_layers': 3, 'd_model': 1024, 'e_layers': 2, 'label_seq_len_ratio': 0.65, 'learning_rate': 4.6096445077520026e-05, 'n_heads': 12, 'seq_len': 63, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=91, value=None),\n",
       " FrozenTrial(number=91, state=TrialState.COMPLETE, values=[0.17096154391765594, 167.08], datetime_start=datetime.datetime(2023, 7, 18, 13, 2, 40, 375545), datetime_complete=datetime.datetime(2023, 7, 18, 13, 3, 28, 60850), params={'batch_size': 48, 'd_layers': 1, 'd_model': 1792, 'e_layers': 7, 'label_seq_len_ratio': 0.675, 'learning_rate': 0.0020942099526299975, 'n_heads': 32, 'seq_len': 98, 'train_epochs': 3}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=92, value=None),\n",
       " FrozenTrial(number=92, state=TrialState.COMPLETE, values=[0.04444005712866783, 178.26], datetime_start=datetime.datetime(2023, 7, 18, 13, 3, 28, 94538), datetime_complete=datetime.datetime(2023, 7, 18, 13, 4, 39, 664441), params={'batch_size': 24, 'd_layers': 2, 'd_model': 1536, 'e_layers': 5, 'label_seq_len_ratio': 0.7000000000000001, 'learning_rate': 0.00316366655952469, 'n_heads': 8, 'seq_len': 91, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=93, value=None),\n",
       " FrozenTrial(number=93, state=TrialState.COMPLETE, values=[0.010538758710026741, 465.51], datetime_start=datetime.datetime(2023, 7, 18, 13, 4, 39, 680069), datetime_complete=datetime.datetime(2023, 7, 18, 13, 5, 12, 288811), params={'batch_size': 32, 'd_layers': 2, 'd_model': 1280, 'e_layers': 4, 'label_seq_len_ratio': 0.8, 'learning_rate': 0.0012271274620245468, 'n_heads': 20, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=94, value=None),\n",
       " FrozenTrial(number=94, state=TrialState.COMPLETE, values=[0.5549933910369873, 320.43], datetime_start=datetime.datetime(2023, 7, 18, 13, 5, 12, 310953), datetime_complete=datetime.datetime(2023, 7, 18, 13, 5, 36, 899129), params={'batch_size': 56, 'd_layers': 3, 'd_model': 1280, 'e_layers': 3, 'label_seq_len_ratio': 0.55, 'learning_rate': 0.0070211387528121465, 'n_heads': 12, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=95, value=None),\n",
       " FrozenTrial(number=95, state=TrialState.COMPLETE, values=[0.04298297315835953, 199.87], datetime_start=datetime.datetime(2023, 7, 18, 13, 5, 36, 914756), datetime_complete=datetime.datetime(2023, 7, 18, 13, 6, 11, 496485), params={'batch_size': 32, 'd_layers': 1, 'd_model': 1792, 'e_layers': 4, 'label_seq_len_ratio': 0.8, 'learning_rate': 2.1989556520305963e-05, 'n_heads': 16, 'seq_len': 49, 'train_epochs': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=96, value=None),\n",
       " FrozenTrial(number=96, state=TrialState.COMPLETE, values=[0.014001655392348766, 277.0], datetime_start=datetime.datetime(2023, 7, 18, 13, 6, 11, 512112), datetime_complete=datetime.datetime(2023, 7, 18, 13, 7, 38, 980933), params={'batch_size': 40, 'd_layers': 3, 'd_model': 1536, 'e_layers': 5, 'label_seq_len_ratio': 0.625, 'learning_rate': 0.0002444079271575832, 'n_heads': 28, 'seq_len': 105, 'train_epochs': 6}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=97, value=None),\n",
       " FrozenTrial(number=97, state=TrialState.COMPLETE, values=[0.009618899784982204, 485.05], datetime_start=datetime.datetime(2023, 7, 18, 13, 7, 38, 998983), datetime_complete=datetime.datetime(2023, 7, 18, 13, 8, 23, 345023), params={'batch_size': 56, 'd_layers': 2, 'd_model': 1536, 'e_layers': 6, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.0005532141393765428, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=98, value=None),\n",
       " FrozenTrial(number=98, state=TrialState.COMPLETE, values=[0.012188228778541088, 367.82], datetime_start=datetime.datetime(2023, 7, 18, 13, 8, 23, 429682), datetime_complete=datetime.datetime(2023, 7, 18, 13, 9, 5, 186530), params={'batch_size': 56, 'd_layers': 2, 'd_model': 1536, 'e_layers': 6, 'label_seq_len_ratio': 0.42500000000000004, 'learning_rate': 0.000627255247777746, 'n_heads': 4, 'seq_len': 63, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=99, value=None),\n",
       " FrozenTrial(number=99, state=TrialState.COMPLETE, values=[0.01883160136640072, 227.17], datetime_start=datetime.datetime(2023, 7, 18, 13, 9, 5, 202155), datetime_complete=datetime.datetime(2023, 7, 18, 13, 10, 4, 457081), params={'batch_size': 48, 'd_layers': 4, 'd_model': 1792, 'e_layers': 3, 'label_seq_len_ratio': 0.5750000000000001, 'learning_rate': 0.002273024983796707, 'n_heads': 24, 'seq_len': 56, 'train_epochs': 5}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'batch_size': IntDistribution(high=64, log=False, low=16, step=8), 'd_layers': IntDistribution(high=4, log=False, low=1, step=1), 'd_model': IntDistribution(high=2048, log=False, low=1024, step=256), 'e_layers': IntDistribution(high=7, log=False, low=2, step=1), 'label_seq_len_ratio': FloatDistribution(high=0.8, log=False, low=0.4, step=0.025), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_heads': IntDistribution(high=32, log=False, low=4, step=4), 'seq_len': IntDistribution(high=112, log=False, low=49, step=7), 'train_epochs': IntDistribution(high=6, log=False, low=3, step=1)}, trial_id=100, value=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"tune_informer_SRL_NEG_00_04_wrmse_26-07-2023_18-03-52.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"./optuna_studies/\"\n",
    "study_paths = [path for path in os.listdir(root_path) if path.startswith('tune_informer_SRL')]\n",
    "study_names = [study_path.removeprefix('tune_informer_SRL').removesuffix('.db') for study_path in study_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['00_04', '08_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\srl_informer\\aggregate_result.ipynb Cell 38\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/srl_informer/aggregate_result.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m times \u001b[39min\u001b[39;49;00m study_paths[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not list"
     ]
    }
   ],
   "source": [
    "times in study_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tune_informer_SRL_NEG_00_04_linex_26-07-2023_03-45-45.db',\n",
       " 'tune_informer_SRL_NEG_00_04_linlin_19-07-2023_22-26-38.db',\n",
       " 'tune_informer_SRL_NEG_00_04_rmse.db',\n",
       " 'tune_informer_SRL_NEG_00_04_w_rmse_26-07-2023_18-03-52.db',\n",
       " 'tune_informer_SRL_NEG_08_12_linex_26-07-2023_05-46-18.db',\n",
       " 'tune_informer_SRL_NEG_08_12_linlin_20-07-2023_06-47-58.db',\n",
       " 'tune_informer_SRL_NEG_08_12_rmse.db',\n",
       " 'tune_informer_SRL_NEG_08_12_w_rmse_26-07-2023_19-42-20.db',\n",
       " 'tune_informer_SRL_POS_00_04_linex_25-07-2023_23-07-22.db',\n",
       " 'tune_informer_SRL_POS_00_04_linlin_19-07-2023_23-39-57.db',\n",
       " 'tune_informer_SRL_POS_00_04_rmse.db',\n",
       " 'tune_informer_SRL_POS_00_04_w_rmse_26-07-2023_13-16-16.db',\n",
       " 'tune_informer_SRL_POS_08_12_linex_26-07-2023_01-34-24.db',\n",
       " 'tune_informer_SRL_POS_08_12_linlin_20-07-2023_01-51-59.db',\n",
       " 'tune_informer_SRL_POS_08_12_rmse.db',\n",
       " 'tune_informer_SRL_POS_08_12_w_rmse_26-07-2023_14-15-02.db']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[path for path in study_paths if check_strings(times, path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tune_informer_SRL_NEG_00_04_linex_26-07-2023_03-45-45.db',\n",
       " 'tune_informer_SRL_NEG_00_04_linlin_19-07-2023_22-26-38.db',\n",
       " 'tune_informer_SRL_NEG_00_04_rmse.db',\n",
       " 'tune_informer_SRL_NEG_00_04_w_rmse_26-07-2023_18-03-52.db',\n",
       " 'tune_informer_SRL_NEG_04_08_linex_26-07-2023_04-43-10.db',\n",
       " 'tune_informer_SRL_NEG_04_08_linlin_20-07-2023_05-57-00.db',\n",
       " 'tune_informer_SRL_NEG_04_08_rmse.db',\n",
       " 'tune_informer_SRL_NEG_04_08_w_rmse_26-07-2023_18-42-01.db',\n",
       " 'tune_informer_SRL_NEG_08_12_linex_26-07-2023_05-46-18.db',\n",
       " 'tune_informer_SRL_NEG_08_12_linlin_20-07-2023_06-47-58.db',\n",
       " 'tune_informer_SRL_NEG_08_12_rmse.db',\n",
       " 'tune_informer_SRL_NEG_08_12_w_rmse_26-07-2023_19-42-20.db',\n",
       " 'tune_informer_SRL_NEG_12_16_linex_26-07-2023_06-54-21.db',\n",
       " 'tune_informer_SRL_NEG_12_16_linlin_20-07-2023_07-47-42.db',\n",
       " 'tune_informer_SRL_NEG_12_16_rmse.db',\n",
       " 'tune_informer_SRL_NEG_12_16_w_rmse_26-07-2023_20-52-17.db',\n",
       " 'tune_informer_SRL_NEG_16_20_linex_26-07-2023_07-48-00.db',\n",
       " 'tune_informer_SRL_NEG_16_20_linlin_20-07-2023_08-50-57.db',\n",
       " 'tune_informer_SRL_NEG_16_20_rmse.db',\n",
       " 'tune_informer_SRL_NEG_16_20_w_rmse_26-07-2023_22-03-55.db',\n",
       " 'tune_informer_SRL_NEG_20_24_linex_26-07-2023_08-47-09.db',\n",
       " 'tune_informer_SRL_NEG_20_24_linlin_20-07-2023_10-08-51.db',\n",
       " 'tune_informer_SRL_NEG_20_24_rmse.db',\n",
       " 'tune_informer_SRL_NEG_20_24_w_rmse_26-07-2023_22-55-30.db',\n",
       " 'tune_informer_SRL_POS_00_04_linex_25-07-2023_23-07-22.db',\n",
       " 'tune_informer_SRL_POS_00_04_linlin_19-07-2023_23-39-57.db',\n",
       " 'tune_informer_SRL_POS_00_04_rmse.db',\n",
       " 'tune_informer_SRL_POS_00_04_w_rmse_26-07-2023_13-16-16.db',\n",
       " 'tune_informer_SRL_POS_04_08_linex_26-07-2023_00-30-13.db',\n",
       " 'tune_informer_SRL_POS_04_08_linlin_20-07-2023_00-39-36.db',\n",
       " 'tune_informer_SRL_POS_04_08_rmse.db',\n",
       " 'tune_informer_SRL_POS_04_08_w_rmse_26-07-2023_13-25-16.db',\n",
       " 'tune_informer_SRL_POS_08_12_linex_26-07-2023_01-34-24.db',\n",
       " 'tune_informer_SRL_POS_08_12_linlin_20-07-2023_01-51-59.db',\n",
       " 'tune_informer_SRL_POS_08_12_rmse.db',\n",
       " 'tune_informer_SRL_POS_08_12_w_rmse_26-07-2023_14-15-02.db',\n",
       " 'tune_informer_SRL_POS_12_16_linex_26-07-2023_01-48-41.db',\n",
       " 'tune_informer_SRL_POS_12_16_linlin_20-07-2023_03-17-40.db',\n",
       " 'tune_informer_SRL_POS_12_16_rmse.db',\n",
       " 'tune_informer_SRL_POS_12_16_w_rmse_26-07-2023_15-09-54.db',\n",
       " 'tune_informer_SRL_POS_16_20_linex_26-07-2023_02-46-42.db',\n",
       " 'tune_informer_SRL_POS_16_20_linlin_20-07-2023_04-08-22.db',\n",
       " 'tune_informer_SRL_POS_16_20_rmse.db',\n",
       " 'tune_informer_SRL_POS_16_20_w_rmse_26-07-2023_15-58-54.db',\n",
       " 'tune_informer_SRL_POS_20_24_linex_26-07-2023_03-35-45.db',\n",
       " 'tune_informer_SRL_POS_20_24_linlin_20-07-2023_04-43-35.db',\n",
       " 'tune_informer_SRL_POS_20_24_rmse.db',\n",
       " 'tune_informer_SRL_POS_20_24_w_rmse_26-07-2023_17-08-37.db']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
