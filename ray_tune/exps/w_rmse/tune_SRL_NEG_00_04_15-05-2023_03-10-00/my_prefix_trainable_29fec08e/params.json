{
  "batch_size": 4,
  "d_layers": 1,
  "d_model": 1024,
  "e_layers": 2,
  "label_seq_len_ratio": 0.55,
  "learning_rate": 0.00010724438745368726,
  "n_heads": 8,
  "seq_len": 70,
  "train_epochs": 8,
  "w_rmse_weight": 3.2
}