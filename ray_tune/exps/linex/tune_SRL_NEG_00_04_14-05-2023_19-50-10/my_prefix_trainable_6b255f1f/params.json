{
  "batch_size": 8,
  "d_layers": 2,
  "d_model": 512,
  "e_layers": 6,
  "label_seq_len_ratio": 0.675,
  "learning_rate": 0.00014187829417526904,
  "linex_weight": 2.7849999999999997,
  "n_heads": 8,
  "seq_len": 56,
  "train_epochs": 13
}